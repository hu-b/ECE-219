{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Project 1\n",
    "\n",
    "Project 1 is **Classification Analysis on Textual Data**, where you extract features from raw texts and try different classification approaches to classify them into topics.\n",
    "\n",
    "During this discussion, we introduce some key concepts and usages of relevant Python packages to help you get started with your project.\n",
    "\n",
    "This explanation are mainly from different sections of the scikit-learn tutorial on text classification available at http://scikit-learn.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & Environment Setup\n",
    "\n",
    "### Anaconda\n",
    "\n",
    "Anaconda is recommended as a popular Python distribution with package & environment managing tools, which provides most of the tools we would use during the course. It supports Windows, macOS and Linux.\n",
    "\n",
    "Anaconda can be downloaded from https://www.anaconda.com/download/. You can follow their official installation instructions at https://docs.anaconda.com/anaconda/install/ to easily install it.\n",
    "\n",
    "If you are new to Python, Python 3.6.\\* is recommended; if you prefer Python 2, it is also fine.\n",
    "\n",
    "### Jupyter\n",
    "\n",
    ">The Jupyter Notebook App is a server-client application that allows editing and running notebook documents via a web browser. The Jupyter Notebook App can be executed on a local desktop requiring no internet access (as described in this document) or can be installed on a remote server and accessed through the internet. <span style=\"margin-top: 1em; float: right;\">--from <a href=\"http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html\">Jupyter/IPython Notebook Quick Start Guide</a></span>\n",
    "\n",
    "Jupyter comes with Anaconda by default, so you can simply start it using the following command at the Terminal (Mac/Linux) or Command Prompt (Windows):\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "See https://jupyter.readthedocs.io/en/latest/running.html#running for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of plotting in Jupyter notebook (`matplotlib`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x109a87630>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW98PHPd7KSEBKy7yRAWBIggBFEXJHVBVxq1Wpd\naut9nltv+9h722p7b3sfW2/tvd2e9ta21qVqW5daEUQQIuKGIETZsrATyJ6QkIXsyfyePzLxJhgI\nZCZzZvm+X695ZebMOXO+gcl853x/mxhjUEoppfrZrA5AKaWUZ9HEoJRSahBNDEoppQbRxKCUUmoQ\nTQxKKaUG0cSglFJqEE0MSimlBtHEoJRSahBNDEoppQYJtDqAkYiNjTUZGRlWh6GUUl7lk08+OWmM\niRtuP69MDBkZGRQUFFgdhlJKeRUROX4++2kpSSml1CCaGJRSSg2iiUEppdQgmhiUUkoNoolBKaXU\nIC5JDCLyjIjUikjhWZ4XEfm1iBwWkb0iMnfAc/eIyCHH7R5XxKOUUmrkXHXF8Cdg+TmeXwFkOW4P\nAL8DEJFo4IfAfGAe8EMRGe+imJRSSo2AS8YxGGPeF5GMc+yyCnje9K0jul1EokQkCbgKyDfGNACI\nSD59CeZFV8TlC4wx7KtooriymR67oafXztjQIK6cEkdcRIjV4Sk1qg5Ut3DsZCsNrV00tHaSGDmG\n+ZnRpI4fg4hYHZ7PctcAtxSgbMDjcse2s23/HBF5gL6rDdLT00cnSg9S1tDGyzvLeGNvJcfr2z73\nvAjMTR/PdTOTuPOSdEICAyyIUinXa+/qZe2eCv68/QT7KpqG3Cc5MpSVs1P4x6snMS40yM0R+j6v\nGflsjHkSeBIgLy/PWBzOqLHbDc9vK+Wnbx2gs6eXhZNj+fpVk1kwKYbQoAACbUJlUztvF9eyqbia\nR9cV85ePj/P4LbO4OCPa6vCVcsrmkhq+/epeGlq7yIofy/9dmcNFE8YTOzaEqLAgSutb2XGsgQ8O\nneQP7x/hbwVl/PPSqdx2cRoBNr2CcBV3JYYKIG3A41THtgr6ykkDt7/rppg8TllDG//ytz18fKyB\nK6fE8R83zyQlaszn9hsfHkxOciTfXJzFlgO1/OvqQm79/TbunJ/OD27I1qsH5XU6e3p5fMN+nt1a\nSnbSOJ64cy7zM6M/Vy6aljiOaYnjuHtBBvvKm/jRumK+t3ofr31azh/vzmN8eLBFv4Fvkb6yvwte\nqK+NYZ0xZsYQz10HPAhcS19D86+NMfMcjc+fAP29lD4FLupvczibvLw842tzJe2vbubOP35MV4+d\nf7s+m1vzUs+7htra2cMv8g/y9IfHuDwrlie/nMeYYE0OyjucPN3Jvc/uoLCimXsvzeCRa6ed95cb\nYwyrd1Xw8Gv7SB0/hufum0dadNgoR+y9ROQTY0zesPu5IjGIyIv0ffOPBWro62kUBGCM+b30fcL9\nN30Ny23AfcaYAsexXwG+53ipx4wxzw53Pl9LDMWVzdz19McEBQgvfu0SJsaNHdHrvFJQxsN/30ve\nhGievjePCK29Kg/X2NbF7U9up7S+lV/fPoelOYkjep2dpQ189bkCggJs/Om+i5mREuniSH2DWxOD\nu/lSYiisaOKupz9mTFAAL37tEjJiw516vTf2VPLQy7vJSR7Hn786X5OD8linO3u486mPKals5ul7\n87g8a9jZoM/pUE0L9zyzg7buXl7/x4VO/y35ovNNDDry2UI1zR3c++wOwoMDefmBBS55I9+Qm8zv\n77qIwspm/vmVPdjt3pf4le/r6O7l/j/tpLCiid/eOdfppACQlRDBiw9cAsBXny+guaPb6df0V5oY\nLNLda+frf/mUtq5envvKxaTHuK4uujg7ge9dO51NxTU88e5hl72uUq7y2JslfHysgV98MZcl2Qku\ne90JMeH87s6LKD3ZyoN/3UVPr91lr+1PNDFY5Cfr91Nw/BQ/vWUWk+MjXP76X1mYwarZyfw8/yBb\nDtS6/PWVGqkN+6p4YftxvnZ5JqtmDzlsySkLJsXwoxtn8P7BOv5j/X6Xv74/0MRggXV7K3lm6zHu\nvTSDG3KTR+UcIsLjN89iWuI4vvniLsoaPj9ITil3K2to4zt/30tuWhTfXjZt1M5zx7x07lkwgWe2\nHuODQ3Wjdh5fpYnBzWqaO3jk7/uYmx7F966dPqrnGhMcwB/uuoheu+F7q/fhjR0NlO/o7rXzjZd2\ngYHf3D6H4MDR/fh55NrpTIwL57uv7qVF2xsuiCYGN/v3tUV09dr5xRdnj/ofBkB6TBjfWT6NDw6d\nZPWuilE/n1Jn88cPjrLrRCM/uWWmS9vUziY0KICf3ZpLdXMH/7G+ZNTP50s0MbhRfnENGwqr+cY1\nWW7tSvflSyYwNz2KR9cVc/J0p9vOq1S/8lNt/HrzIZblJHD9rNEpnw5lbvp4vnb5RF7cUcb7B7Wk\ndL40MbjJ6c4efrCmkKkJETxwxUS3nttmE356yyzaOnt59I1it55bKYD/+0YxgvCDG3Lcfu6Hlkxh\nUlw4j7y2j/auXref3xtpYnCTn208QHVzBz+5ZSZBAe7/Z89KiODrV09m7Z5K3tNvTsqNNpfUkF9c\nwzcXZw0599doCw0K4Cc3z6KisZ2nPjjq9vN7I00MbnCopoXnt5Vy5/x05qZbtw7R/75qEhNiwvjJ\n+hJ6deCbcoP2rl5+uLaIrPixfGVhpmVxzMuMZnlOIr977wi1zR2WxeEtNDG4wX9tPEBYcCDfWjLV\n0jiCA218e9lU9le38Nqn5ZbGovzDM1uPUX6qnUdXzXBLZ4tzeXjFNLp77fx800FL4/AGmhhG2SfH\nT7GpuIZ/uGIi0R4wJfB1M5PITY3kF/kH6ejWeqsaPU3t3fzhvSMsnh7PgkkxVodDRmw49yzI4JVP\nyiiubLY6HI+miWEUGWP46Yb9xI4N4f7LrbuMHkhEeOTa6VQ1dfDs1lKrw1E+7I/vH6W5o8fyK+WB\n/mlRFpFjgnhsfbGO6zkHTQyjaMuBWnaUNvDNayYTFuw5i+VdMjGGRdPieeLdw5xq7bI6HOWDTp7u\n5Jmtx7ghN5ns5HFWh/OZyLAg/mlRFlsP17P96DmXffFrmhhGid1u+M+3DpARE8bt8zxvjeqHV0zj\ndGcPT2ovDTUKnthyhM4eOw8tzrI6lM+5c346sWND+M07h6wOxWO5JDGIyHIROSAih0Xk4SGe/6WI\n7HbcDopI44Dnegc8t9YV8XiCTcU17K9u4aElUyzpnjqcKQkRXDsziRe2HaepXacLUK5T2djOn7cf\n5wtzU0e86NRoCg0K4H9dOZGPjtRTUKpXDUNx+hNLRAKA3wIrgGzgDhHJHriPMeYhY8xsY8xs4DfA\nawOebu9/zhiz0tl4PIExht+9d4T06DCum5lkdThn9Y9XTeJ0Zw8vbCu1OhTlQ558/ygGwzc88Gqh\n35fmpxMdHsyv39Fp6Yfiiq+y84DDxpijxpgu4CVg1Tn2vwN40QXn9VjbjtSzp6yRf7hyIoEeeLXQ\nLyc5kqunxvHM1lLaunqsDkf5gIbWLl7aeYIbZ6dYMpjtfIUFB/LVyzN5/2Adu8sahz/Az7jiUysF\nKBvwuNyx7XNEZAKQCbwzYHOoiBSIyHYRudEF8VjuiXePEBcRwi1zU60OZVgPLprc98e8o2z4nZUa\nxgvbjtPRbXf7tC8jcfeCDCLHBPHf2tbwOe7+Ons78KoxZmAH+gmONUi/BPxKRCYNdaCIPOBIIAV1\ndZ47pcPe8kY+PHyS+y/LJDQowOpwhnXRhGjmZ0bz5PtH6erR1a7UyLV39fLctlIWT48nK8H1i0+5\n2tiQQL6yMJO3S2o5UN1idTgexRWJoQJIG/A41bFtKLdzRhnJGFPh+HkUeBeYM9SBxpgnjTF5xpi8\nuDjn14cdLb979wgRoYHcOd/zeiKdzdevnkx1cwerd+loaDVyr35SRkNrFw9cMeR3O49094IJhATa\neHbrMatD8SiuSAw7gSwRyRSRYPo+/D/Xu0hEpgHjgW0Dto0XkRDH/VhgIeC103+WnmzlraJq7l4w\ngYjQIKvDOW+XZ8UyPWkcz24t1UE/akR6eu388YNjzEmP4uIM6+YDu1Djw4O5eW4qq3dV0KBjej7j\ndGIwxvQADwIbgRLgFWNMkYg8KiIDexndDrxkBn/yTAcKRGQPsAV43BjjtYnh+W3HCRDhngUZVody\nQUSE+y7NYH91iw76USPyVlE1Jxra+IcrJiEiVodzQb6yMIPOHjsv7jhhdSgewyXDcY0x64H1Z2z7\nwRmP/32I4z4CZroiBqu1dvbwt4IyVsxMIn5cqNXhXLCVs5P5yYYSnvuo1CPmtVHe5bmPSpkQE8aS\n7ASrQ7lgWQkRXJ4Vy/PbSvna5RMtn+zPE+i/gIus3lVBS2cP9146wepQRiQ0KIDb56Wzqbia8lNt\nVoejvEhJVTM7S09x1/wJBNi862qh31cWZlLT3MmGwiqrQ/EImhhcwBjD89tKmZEyztL1Fpx11yV9\nSe2F7cctjkR5kxe2Hyck0MateZ7fPftsrpwSx8TYcJ7+8Ji2s6GJwSW2Ha3nYM1p7l6Q4XX11YFS\nosawLCeRl3eW6RKI6rw0d3Tz+q4KVuYmExVm/bTyI2WzCfctzGBveRO7dMCbJgZXeO6jUsaHBbEy\n132LnI+Wey7NoLGtmzW7z9bjWKn/8don5bR19XK3l3W4GMqNc1IICw7gJW2E1sTgrMrGdvKLa7jt\n4nSvGNA2nPmZ0UxNiOCv+sehhmGM4YXtx8lNi2JmaqTV4TgtIrTvy90be6po7vDviSU1MTjpbwXl\n2A1eNaDtXESE2+elsbe8iaLKJqvDUR5s25F6jtS1cvcl3tnhYih3zEunvbuXNbsrrQ7FUpoYnGC3\nG14pKOOyybGkRYdZHY7L3DQnheBAGy/v1PmT1Nn9ZccJosKCuG6W584gfKFmpUaSnTSOv358wq8b\noTUxOGHrkZNUNLZz28Vpw+/sRaLCglkxI5HVuyp0XWg1pFOtXeQX1XDTnBSfKKH2ExHumJ9OSVUz\ne8v994pZE4MTXtpZRlRYEEtzvG9Qz3BuuziNlo4e7dethrRmdwVdvXZuvci3vhQBrJqdzJigAL8e\nCa2JYYQaBnxjCgn0nW9M/S7JjGFCTBgv6nTcagivFJQzMyXSo9ZzdpVxjkbotXsqafHTRmhNDCO0\nelffNyZfKyP1s9mE2y5OY8exBo7WnbY6HOVBCiuaKK5q5otePKBtOLfPS6Otq5d1e/3zilkTwwgY\nY3hlZxm5aVFMS/S9b0z9vjA3lQCbaCO0GuRvBWUEB9pYmTvkelw+YXZaFBPjwnntU/+cil4Twwjs\nKW/iQE0Lt+X55tVCv/hxoVw9NY7Xd1fQa/ffHhrqf3R09/L67kqW5yQSGeY9U8tfKBHhlrmp7Cw9\nxfH6VqvDcTtNDCOw+tNyQgJtXJ/rO930zuamOanUNHfy0ZGTVoeiPEB+cQ1N7d180ce/FEFft20R\neO1T/5sFQBPDBerutfPG3ioWZycwzosW4xmpa6bHExEa6Jd/HOrzXv2knJSoMVzqB1OzJzt+z9d2\nlWP3sytmTQwX6L0DdTS0dnHzHN+trw4UGhTA9bOSeKuwmtbOHqvDURaqa+nkg0N13DgnGZuXTq99\noW6Zm0pZQzsFx09ZHYpbuSQxiMhyETkgIodF5OEhnr9XROpEZLfj9tUBz90jIocct3tcEc9oWr2r\ngpjwYK6Y4rnrTrvazXNTae/u5a3CaqtDURZat7cSu4EbZ/vHlyKA5TMSCQsO4O+f+FcjtNOJQUQC\ngN8CK4Bs4A4RyR5i15eNMbMdt6ccx0YDPwTmA/OAH4qIxy5o0NTeTX5JDTfkJhMU4D8XW3kTxpMW\nPYbVu7Sc5M9e31VBTvI4shIirA7FbcKCA1kxI4k391X51SwArvh0mwccNsYcNcZ0AS8Bq87z2GVA\nvjGmwRhzCsgHlrsgplGxYV8VXT12bvKTMlI/EeGmOalsPXKS6qYOq8NRFjhad5o95U1+994HuOWi\nFE539rCpuMbqUNzGFYkhBRjY0b3cse1Mt4jIXhF5VUT6uzSc77Ee4bVdFUyMDWeWD0wxfKFumpOC\nMfC6rtPgl17fXYkI3OADa45cqEsyY0gcF8paP5px1V31kDeADGPMLPquCp670BcQkQdEpEBECurq\n6lwe4HDKT7Wx41iDowubfzS8DZQZG86c9Che13KS3zHG8PquChZOiiVhXKjV4bidzSZcPyuJ9w7W\n0tjWZXU4buGKxFABDOzUnOrY9hljTL0xptPx8CngovM9dsBrPGmMyTPG5MXFub/h9409fUPjb/TD\nS+l+q3KT2V/dwqGaFqtDUW60q6yREw1tfv3eXzk7me5e4zcdMFyRGHYCWSKSKSLBwO3A2oE7iMjA\nkWArgRLH/Y3AUhEZ72h0XurY5nHe2FPJnPQon1p34UJdOysJm8Abfjp/jL96fVcFIYE2lvngLMLn\na2ZKJJmx4azd4x/lJKcTgzGmB3iQvg/0EuAVY0yRiDwqIisdu31DRIpEZA/wDeBex7ENwI/oSy47\ngUcd2zzK4drTFFc1c8Ms/6uvDhQfEcolE2NYt6fSrxcx8Sc9vXbW76ti8fQEIvxgQOfZiAg35Caz\n7Wg9tc2+3wHDJW0Mxpj1xpgpxphJxpjHHNt+YIxZ67j/iDEmxxiTa4y52hizf8CxzxhjJjtuz7oi\nHldbt7ev4c2XVqoaqRtykzl6spWiymarQ1Fu8PGxBk6e7uIGP5j+ZTgrc5MxBr+YcdV/OuOPkDGG\nN/ZUMi8j2i8b3s60PCeRQJvwhp9cUvu7dXsrCQ8O4Kqp8VaHYrnJ8WPJThrHGj9472tiGMb+6haO\n1LX6ZTe9oYwPD+byrFjW7a3yu/lj/E13r50NhdUszk7wqeU7nbFydjJ7yhp9fsZVTQzDeGNPJQE2\nYcWMRKtD8RgrZydT0djOrjL/mj/G32w9fJLGtm6u9/O2tYH6vyD6ejlJE8M5GGNYt7eKSyfFEDM2\nxOpwPMbi6QmEBNo+68KrfNO6vVVEhAZyxZRYq0PxGClRY5iTHsWbmhj8197yJk40tGkZ6QwRoUFc\nPTWeN/dV6QI+Pqqzp5eNRdUszU70yTXNnXHdzCSKq5opPem75SRNDOfw5r4qggKEZdlaRjrTtbOS\nqGvp5BM/m47YX3xw8CQtHT1+sRjVhVoxs+/f5M19vnvVoInhLIwxrN9XxWWTY316CcORWjQtnpBA\nG+t9+I/Dn725r4rIMUEsnKRlpDOlRI1hdlqUT7/3NTGcRWFFM+Wn2j/7dqAGGxsSyJVT4thQqL2T\nfE1nTy9vF9ewLCeB4ED9iBjKdTOTKKps9tneSfq/fhbrC6sItAlLs/13GoDhXDcriZrmTu2d5GO2\nHj5JS2ePfik6hxUz+8rLvlpO0sQwBGMMG/ZVsWBSDFFhwVaH47EWTYsnOMDGm3v9Y2Ixf7F+XzUR\noYFaRjqH1PFh5PpwOUkTwxBKqloorW/jWv3GdE4RoUFcMSVWy0k+pLvXTn5xDUumaxlpONfNTKSw\nopkT9W1Wh+Jy+j8/hA2FVdgELSOdh2tnJlHV1MGe8karQ1EusO1IPU3t3SzXAZ3DWjHDd3snaWI4\ngzGGN/dVcclEHdR2Pq6ZnkBQgPjsJbW/2VBYTXhwAFdMcf+aJ94mLTqMWamRbCzyvVKqJoYzHKw5\nzdG6Vm14O0+RY4K4PCuO9fuqdSpuL9drN2wqqubqafE6N9J5WpaTyO6yRqqa2q0OxaU0MZxhQ2EV\nIvj1oiQXanlOIhWN7ToVt5fbcayB+tYubVu7AP0lt40+trKbJoYzvFVYTd6E8cRH6BTb52txdgI2\nwScvqf3JhsIqQoNsXDVVy0jna1LcWLLix/KWj733XZIYRGS5iBwQkcMi8vAQz39LRIpFZK+IbBaR\nCQOe6xWR3Y7b2jOPdafj9a3sr25hWY42vF2I6PBg5mVG+816uL7IbjdsLKrmyilxhAUHWh2OV1k+\nI7Hvaut05/A7ewmnE4OIBAC/BVYA2cAdIpJ9xm67gDxjzCzgVeA/BzzXboyZ7bitxEL933g1MVy4\n5TmJHKo9zZG601aHokZgd3kjNc2d2htpBJblJGI38HZJjdWhuIwrrhjmAYeNMUeNMV3AS8CqgTsY\nY7YYY/o7+24HUl1wXpfbWFRDdtI40qLDrA7F6yx1JFMtJ3mnjUXVBNqERVO1be1C5SSPIy16jE9d\nMbsiMaQAZQMelzu2nc39wIYBj0NFpEBEtovIjWc7SEQecOxXUFdX51zEQ6ht7uDTE6f0G9MIJUeN\nITc1ko1FvvOtyV8YY9hUVMOCSTE6YeQIiAjLcxLZerie5o5uq8NxCbc2PovIXUAe8F8DNk8wxuQB\nXwJ+JSKThjrWGPOkMSbPGJMXF+f6xrFNxTUYo2UkZyybkcgeH+y65+sO1Z7m2MnWz6761IVbPiOR\nrl47W/bXWh2KS7giMVQAaQMepzq2DSIii4HvAyuNMZ+10hhjKhw/jwLvAnNcENMF21hUTWZsOFMS\nxlpxep/Qn1Q36VWDV+nvaqkj/UduTtp44iJCfKaU6orEsBPIEpFMEQkGbgcG9S4SkTnAH+hLCrUD\nto8XkRDH/VhgIVDsgpguSFN7N9uO1LM0JwERcffpfcZnXfd8qNbqDzYWVzMnPYqEcdpFe6RsNmFJ\ndgLvHqijo7vX6nCc5nRiMMb0AA8CG4ES4BVjTJGIPCoi/b2M/gsYC/ztjG6p04ECEdkDbAEeN8a4\nPTG8s7+GHrvRMpILLMtJ5ONj9TS0dlkdijoP5afaKKxo1ve+CyzNTqCtq5ePjpy0OhSnuaTDsjFm\nPbD+jG0/GHB/8VmO+wiY6YoYnLGpqIb4iBBmp0ZZHYrXW5aTyH9vOcw7+2v5wkUe2flMDdBf9tPE\n4LxLJ8USERLIpqIaFk3z7rKc34987uju5b2DdSzNScBm0zKSs2akjCMpMpRNPlJr9XUbi6qZkjCW\nzNhwq0PxesGBNq6aFs/bJTX0evk09H6fGD46cpK2rl6WZOs3JlcQ6au1vn+ojvYu76+1+rKG1i52\nljawVN/7LrM0O4GTp7vYdcK7VzX0+8SwqaiGiJBAFkyMsToUn7E0O5GObjsfHHL9eBPlOptLarBr\nF22XumpqHMEBNjYVe3fPPL9ODL12w9slNVw1LV5Xq3Kh+ROjiQgNJN/L/zh8XX5xDUmRocxIGWd1\nKD4jIjSISyfHsLHIu6eh9+tPw10nTnHydJf233axoAAb1zhqrT29dqvDUUNo7+rl/UN1LMnWLtqu\ntjQ7keP1bRys8d55w/w6MeQX1xAUIDrN8ChYmpPIqbZuPjnu3bVWX/Xh4ZN0dNtZol+KXG5xdjzi\n5dPQ+21iMKZvmuEFk2KJCNX5YVztiilxBAd6f63VV20qqiYiNJD5mdq25mrxEaHMSYvy6lKq3yaG\nw7WnKa1v0zLSKBkbEshlk2O9vtbqi3rths37a7l6qratjZYl2Ynsq2jy2nnD/PZd0f9NVi+lR8+S\n7ATKT7Wzv7rF6lDUAJ8cP0VDaxdLdfnaUdP/ufK2l141+HViyE3T+WFG0zXT+2qt3nxJ7Yvyi6sJ\nChCunKJta6NlcvxYJsaGe20p1S8TQ01zB3vKGrWMNMriI0KZ7eW1Vl9jjGFTcU3f9A3atjaqlmQn\nsP2od67R4JeJoX8JPi0jjb4l2QleXWv1NYdqT3O8vk3f+26wJDuB7l7Dewe8b6CnXyaG/OIaJsSE\nkRWvay+MtqVeXmv1NfnatuY2c9LHExMe7JVXzH6XGE539vDR4XqWTNeBPe4wKa5vgjZvrbX6mk3F\nNeSmRmrbmhsE2IRrpsez5UAt3V420NPvEsP7B+vo6tWBPe7SP6met9ZafUl/25q+991nSXYiLR09\nfHy0wepQLohLEoOILBeRAyJyWEQeHuL5EBF52fH8xyKSMeC5RxzbD4jIMlfEcy75xTWMDwviognj\nR/tUysGba62+5H/a1nTSPHe5bHIsoUE28ou9axS004lBRAKA3wIrgGzgDhHJPmO3+4FTxpjJwC+B\nnzqOzaZvKdAcYDnwhOP1RkV3r5139tdy9bR4AgP87mLJMnO9uNbqS94uriE9OkzXNXejMcEBXJ4V\nR35xjVcN9HTFp+M84LAx5qgxpgt4CVh1xj6rgOcc918FrpG+Av8q4CVjTKcx5hhw2PF6o2JnaQNN\n7d3aTdXNAmzComneWWv1Fa2dPWw9Uq+T5llgyfQEKps6KKpstjqU8+aKxJAClA14XO7YNuQ+jjWi\nm4CY8zzWZfKLawgOtHF5lg7scbcl2QleWWv1Fe8frKOrx87i6fqlyN0WeeFAT6+pp4jIAyJSICIF\ndXUjq1V3dNu5Zlo84SEuWepaXYDLs+IIDbJ9VudW7pVfXENUWBAXZ2jbmrvFjg3hovTxfpcYKoC0\nAY9THduG3EdEAoFIoP48jwXAGPOkMSbPGJMXFzeyb/w/uXkmT9w5d0THKueMCQ7gssneV2v1BT29\ndt45UMuiqdq2ZpUl2QkUVzVT0egdAz1d8S7ZCWSJSKaIBNPXmLz2jH3WAvc47n8BeMf0fTqsBW53\n9FrKBLKAHS6I6ay0vmqdJdnxVDS2U1zlPbVWX7Cz9BSNbd3aTdVC3japntOJwdFm8CCwESgBXjHG\nFInIoyKy0rHb00CMiBwGvgU87Di2CHgFKAbeAr5ujNEV5H3UomkJXldr9QX9bWtX6KR5lpkYN5ZJ\nceFe8953SbHdGLMeWH/Gth8MuN8B3HqWYx8DHnNFHMqzxUWEMNdRa/0/i6dYHY5fMMaQX1LNwkkx\n2rZmsSXZiTz1wVGa2ruJHOPZExhqwVG51ZLsBIoqvafW6u0O1LRQ1tCug9o8wJLsBHrshncP1Fod\nyrA0MSi38rZaq7fLL+r7d148Pd7iSNSctChix4Z4RTlJE4Nyq0lxY5noRbVWb5dfUsPstCjiddI8\ny9lswuLp8bx3oG9MiSfTxKDcrn9SvaZ2nVRvNFU3dbC3vEl7I3mQJdkJtHT2sP1ovdWhnJMmBuV2\nS72o1urlg0HlAAAXNklEQVTN8h2DCXUKGM+xcHIsYcEBbPLwSfU0MSi3m502ntixIbpGwyjLL64h\nIyaMyboglccIDQrgiqw43i6u9eiBnpoYlNsFDKi1dvbosJXR0NLRzbYjJ3XSPA+0NCeB6uYO9lU0\nWR3KWWliUJZYmpPA6c4eth3x7Fqrt3rvYB3dvUa7qXqgRdPiCbAJm4o894pZE4OyxKWT+mqt2jtp\ndGwsqiEmPFgXpPJAUWHBXJzh2ZPqaWJQlggNCuDKKX2T6tntnltr9UadPb1s2V/L4ukJBNi0jOSJ\nlmYncqCmheP1rVaHMiRNDMoyS3MSqG3pZE95o9Wh+JTtRxs43dnD0hztjeSp+rsQe+pVgyYGZZmr\np/bVWj31j8NbbSqqJiw4gIWTY60ORZ1FWnQY0xIjPLadQRODskxUWDDzM6O126oL2e2G/OIarpwS\nR2jQqC2frlxgaU4iBccbOHm60+pQPkcTg7LUkuwEDtee5mjdaatD8Ql7yhupbenUMpIXWJaTgN3A\nZg9c1VATg7LU0py+7pQbPfSS2ttsKq4hwCYsmqqJwdNlJ40jdfwYj3zva2JQlkqJGsPMlEg2Fnn2\nFAHeYlNRNZdMjCYyzLPn+1d9q0kuy0nkw0MnOd3ZY3U4gziVGEQkWkTyReSQ4+fnOk2LyGwR2SYi\nRSKyV0RuG/Dcn0TkmIjsdtxmOxOP8k7LchLYXdZIdVOH1aF4tSN1pzlS18pSHdTmNZZmJ9DVa/e4\necOcvWJ4GNhsjMkCNjsen6kNuNsYkwMsB34lIlEDnv+2MWa247bbyXiUF1rmKCfle/jEYp6u/6pL\nZ1P1HnkZ0cSEB3tcOcnZxLAKeM5x/zngxjN3MMYcNMYcctyvBGoBXXxWfWZyfN8aDZ72x+FtNhZW\nk5saSXLUGKtDUeepb96wBLbsr/WoecOcTQwJxpgqx/1q4JxfVURkHhAMHBmw+TFHiemXIhLiZDzK\nC/XXWrcfraepTddoGImKxnb2lDexbIaWkbzNshmeN2/YsIlBRN4WkcIhbqsG7mf65pA969wGIpIE\nvADcZ4zpX77oEWAacDEQDXz3HMc/ICIFIlJQV1c3/G+mvMqynER67IbN+/WqYSQ2OcpIy3M0MXib\nSyfFEh4c4FFXzMMmBmPMYmPMjCFua4Aaxwd+/wf/kC0oIjIOeBP4vjFm+4DXrjJ9OoFngXnniONJ\nY0yeMSYvLk4rUb5mVkokieNCeatQ2xlG4q3CaqYkjGVinK694G1CgwK4amo8+cU19HrIvGHOlpLW\nAvc47t8DrDlzBxEJBlYDzxtjXj3juf6kIvS1TxQ6GY/yUjabsCwngfcP1dHe5Tm1Vm9Qf7qTnaUN\nerXgxZbNSOTk6U4+OX7K6lAA5xPD48ASETkELHY8RkTyROQpxz5fBK4A7h2iW+pfRGQfsA+IBX7s\nZDzKiy3LSaSj2857Bz2r656ne7ukBrtB2xe82KJp8QQH2thQWDX8zm4Q6MzBxph64JohthcAX3Xc\n/zPw57Mcv8iZ8yvfMi8zmvFhQWworGb5jCSrw/EabxVWkxY9huykcVaHokZobEggV2TFsbGwmh9c\nn235qns68ll5jMAAG8tyEtlc4lld9zxZc0c3Ww/Xsyw70fIPE+WcFTMSqWzqYE+59Ut+amJQHmX5\njEROd/bw4aGTVofiFbbsr6Wr185yLSN5vcXTEwi0CRv2WV9O0sSgPMqlk2IZFxrI+n3aO+l8rN9X\nRcK4EOam6xKe3i4yLIhLJ8eyobCavt7/1tHEoDxKcKCNxdkJ5BdX09VjH/4AP9ba2cO7B+pYMSMJ\nmy7h6RNWzEjkREMbxVXNlsahiUF5nGtnJNHc0cO2o54zEtQTvbO/ls4eOyu0jOQzlmYnYBMsH8+j\niUF5nMuyYhkbEugRtVZPtn5fFXERIeRlRFsdinKRmLEhzM+MYYMmBqUGCw0KYNG0eDYWVdPTq+Wk\nobR19bDlQC0rZiQSoGUkn3LtzEQO157mYE2LZTFoYlAe6dqZiZxq62b70QarQ/FIW/bX0dFt59qZ\nOt7D1yybkYhNYN1e666YNTEoj3TllHjCggN4U8tJQ1q/r4rYsSFcrGUknxMfEcr8zBjW7a20rHeS\nJgblkcYEB7B4egIbCqvo1nLSIO1dvbyzv5blMxK0jOSjrs9N4mhdK/urrSknaWJQHuv6WUk0tnWz\n9bAOdhtoy4Fa2rt7tYzkw5bn9LUdrdtbacn5NTEoj3Xl1DgiQgItrbV6onV7K4l19F5RvilmbAiX\nToph3d4qS8pJmhiUxwoJDGBJTgIbi6p17iSHlo5uNpfUcv2sJC0j+bjrZiZxvL6Nokr3D3bTxKA8\n2g25ybR09PD+QS0nAeQX19DZY+eG3GSrQ1GjbFlOIoE24Q0LykmaGJRHu2xyLFFhQZbVWj3NG3sq\nSYkaw9z0KKtDUaNsfHgwCyfH8qYF5SRNDMqjBQXYWJ6TyNvFNX6/stup1i4+OHSSG3KTdYptP3H9\nrCTKT7Wzq6zRred1KjGISLSI5IvIIcfPIad4FJHeAau3rR2wPVNEPhaRwyLysmMZUKUGuSE3mdau\nXrYc8O+V3dYXVtFjN9yQq72R/MWyGYmEBNpYs6vCred19orhYWCzMSYL2Ox4PJR2Y8xsx23lgO0/\nBX5pjJkMnALudzIe5YPmZ0YTOzaENbvd+8fhad7YU8mkuHBdqc2PjAsNYvH0BNbtde94HmcTwyrg\nOcf954Abz/dA6bsWXgS8OpLjlf8IDLCxMjeZLfvraGzrsjocS1Q3dfDxsQZW5qZoGcnPrJqdTH1r\nFx+6cTyPs4khwRjT38m8Gkg4y36hIlIgIttFpP/DPwZoNMb0OB6XAylOxqN81M1zU+jqtfvtAj59\n0yOgZSQ/dNXUeCLHBLm1nBQ43A4i8jYw1ITv3x/4wBhjRORsTecTjDEVIjIReEdE9gEXtLCpiDwA\nPACQnp5+IYcqH5CTPI7J8WN5fVcFX5rvf///r31aQW5qJBPjxlodinKz4EAb185MYs3uCtq6eggL\nHvZj22nDXjEYYxYbY2YMcVsD1IhIEoDj55Ctg8aYCsfPo8C7wBygHogSkf7fMhU4a0o0xjxpjMkz\nxuTFxcVdwK+ofIGIcNOcFHaUNlDW0GZ1OG5VUtVMcVUzN89NtToUZZEbZyfT1tVLfnGNW87nbClp\nLXCP4/49wJozdxCR8SIS4rgfCywEik1fx9wtwBfOdbxS/VbN7hvU5W+N0Kt3VRBoEx3U5scuzogm\nOTKU191UTnI2MTwOLBGRQ8Bix2NEJE9EnnLsMx0oEJE99CWCx40xxY7nvgt8S0QO09fm8LST8Sgf\nljo+jHmZ0azeVWH5Yunu0tNrZ/WuCq6eFk90uPbm9lc2m7BydgrvHzpJ/enOUT+fU8UqY0w9cM0Q\n2wuArzrufwTMPMvxR4F5zsSg/MtNc1J45LV9FFY0MzM10upwRt3WI/XUtXRyy1ztl+HvbpqTQkVj\nO21dvYz29Ik68ll5lWtnJhEcaOPvn5ZbHYpbvPZpOZFjgrh6WrzVoSiLTU2M4Dd3zCEtOmzUz6WJ\nQXmVyDFBLM1O4PXdFT4/42pLRzcbi6q5ITeJkMAAq8NRfkQTg/I6t12cRmNbt9t6aFhlQ2E1Hd12\n7Y2k3E4Tg/I6CyfFkhI1hpd3llkdyqh6ZWcZE2PDmZOmM6kq99LEoLyOzSZ84aJUPjx8kvJTvjmm\n4WBNCwXHT3H7vDSdAkO5nSYG5ZVuzesrr7z6iW82Qr+0o4ygAOEWLSMpC2hiUF4pdXwYl02O5W8F\n5djtvjWmoaO7l9d2lbM0O5GYsSFWh6P8kCYG5bW+mJdGRWM7Hx2ptzoUl9pYVE1jWze3z0uzOhTl\npzQxKK+1JDuBqLAgXtxxwupQXOqlHWWkRY9h4aRYq0NRfkoTg/JaoUEB3HpRKhuLqqlp7rA6HJco\nPdnKtqP13JaXhs2mjc7KGpoYlFe765IJ9BrDXz/2jauGF3eeIMAm3JqnZSRlHU0MyqtNiAnnqilx\n/HXHCbp63Lf04Who7+rl5Z1lLJmeQMK4UKvDUX5ME4PyencvyKCupZONRd69utvruytobOvmvoUZ\nVoei/JwmBuX1rpwSR3p0GC9sO251KCNmjOHZrceYnjSOeZnRVoej/JwmBuX1bDbhy5dMYEdpAyVV\nzVaHMyLbjtRzsOY09y3M0JHOynKaGJRPuDUvlZBAG89vK7U6lBF5ZmspMeHBrNRV2pQHcCoxiEi0\niOSLyCHHz/FD7HO1iOwecOsQkRsdz/1JRI4NeG62M/Eo/xUVFszNc1P5+6cV1LZ4V9fVE/VtbN5f\nw5fmpxMapNNrK+s5e8XwMLDZGJMFbHY8HsQYs8UYM9sYMxtYBLQBmwbs8u3+540xu52MR/mxf7hi\nIj29dp7dWmp1KBfkTx+VEiDCXZdMsDoUpQDnE8Mq4DnH/eeAG4fZ/wvABmOMb06JqSyVERvOihlJ\n/Hn7cVo6uq0O57w0tHbx0s4T3JCbrF1UlcdwNjEkGGOqHPergYRh9r8dePGMbY+JyF4R+aWInHXG\nMBF5QEQKRKSgrq7OiZCVL/tfV06ipaPHawa8Pbv1GG1dvfzjVZOsDkWpzwybGETkbREpHOK2auB+\nxhgDnHWaSxFJAmYCGwdsfgSYBlwMRAPfPdvxxpgnjTF5xpi8uLi44cJWfmpmaiQLJ8fw9IfHPH7p\nz+aObv70USkrZiSSlRBhdThKfWbYxGCMWWyMmTHEbQ1Q4/jA7//grz3HS30RWG2M+ewa3xhTZfp0\nAs8C85z7dZSC/33lZGpbOln9aYXVoZzTC9uO09LRw9evnmx1KEoN4mwpaS1wj+P+PcCac+x7B2eU\nkQYkFaGvfaLQyXiUYuHkGGamRPLEu0fo7vXMaTLaunp46oOjXD01jhkpkVaHo9QgziaGx4ElInII\nWOx4jIjkichT/TuJSAaQBrx3xvF/EZF9wD4gFvixk/EohYjw0JIsTjS0eey60H/9+ASn2rp5cFGW\n1aEo9TmBzhxsjKkHrhliewHw1QGPS4GUIfZb5Mz5lTqbq6fGc3HGeH69+RC3zE1lTLDnjA9o6ejm\n9+8d4dJJMVw04XNDf5SynI58Vj5JRPjO8mnUtnTyp49KrQ5nkD+8d5STp7v47vJpVoei1JA0MSif\ndXFGNFdPjeP37x2hqd0zxjVUNbXz1IdHWZmbTG5alNXhKDUkTQzKp3172TSa2rv5w3tHrA4FgJ9v\nOojdDt9eNtXqUJQ6K00MyqdlJ4/jxtnJPPXhMUpPtloaS3FlM3//tJx7F2aQFh1maSxKnYsmBuXz\nHrl2OsEBNv5tTSF94zDdzxjDj98sJnJMEF+/SsctKM+miUH5vIRxofzL0il8cOgk6/ZWDX/AKPjb\nJ+V8dKSef14yhciwIEtiUOp8aWJQfuHLCzKYmRLJo+uK3d4QXdPcwY/WFTMvM5o75+sMqsrzaWJQ\nfiHAJvzHTTOpP93JzzYecNt5jTF8f3UhXT12fnrLLGw2XZ1NeT5NDMpvzEyN5N5LM3lh+3E2l9S4\n5Zxv7K3i7ZIa/mXpVDJjw91yTqWcpYlB+ZXvLJ9KdtI4vvXKHspPje6yICfq2/jBmkJy06L4ymWZ\no3oupVxJE4PyK6FBATxx51zsdsODf91FV8/oTLLX2tnD154vwBj4f7fNJkBLSMqLaGJQficjNpz/\n/MIsdpc18pMNJS5/fbvd8K1XdnOotoX//tIcMrSEpLyMJgbll1bMTOK+hRk8u7WUJ9497NLX/vU7\nh9hYVMP3rp3O5Vm6qJTyPk7NrqqUN/vX67JpaO3iP986QJDNxteumOjU6xlj+O2Ww/zq7UPcPDeF\n+7VdQXkpTQzKbwXYhJ/fmkuP3fDY+hJsNhnxh7ndbvjxmyU8s/UYN89J4ae3zKJv/SmlvI9TpSQR\nuVVEikTELiJ559hvuYgcEJHDIvLwgO2ZIvKxY/vLIhLsTDxKXajAABu/um02K2Yk8qN1xTz08m6a\nOy5sAFxLRzffemU3z2w9xlcWZvKzW3MJCtAqrfJezr57C4GbgffPtoOIBAC/BVYA2cAdIpLtePqn\nwC+NMZOBU8D9Tsaj1AULCrDxmzvm8NDiKazdU8mKX33AtiP1wx5njGHN7goW/fw91uyp5NvLpvJv\n10/XQWzK6zm7glsJMNwl8zzgsDHmqGPfl4BVIlICLAK+5NjvOeDfgd85E5NSIxEYYOObi7O4Ykos\nD728mzv+uJ3ctChuvSiVG3KTiRzzP/Mbnahv471DdazdXcHO0lPMSo3kqbvzdH0F5TPc0caQAgxc\neLccmA/EAI3GmJ4B2z+3/KdS7jQnfTxvfuNyXtxxgr8VlPOvrxfyb2sKGRscSHhIICJQ1dQBQOr4\nMfz4xhncMS9dxykonzJsYhCRt4HEIZ76vjFmjetDOmscDwAPAKSnp7vrtMoPhYcE8tXLJ3L/ZZkU\nVjTzdkkNzR3dtHb20NVjJzctiiunxJEZG64NzMonDZsYjDGLnTxHBZA24HGqY1s9ECUigY6rhv7t\nZ4vjSeBJgLy8PGsm1Vd+RUSYmRrJzNRIq0NRyq3c0XViJ5Dl6IEUDNwOrDV9K6ZsAb7g2O8ewG1X\nIEoppYbmbHfVm0SkHFgAvCkiGx3bk0VkPYDjauBBYCNQArxijClyvMR3gW+JyGH62hyediYepZRS\nzhOrljp0Rl5enikoKLA6DKWU8ioi8okx5qxjzvrpKByllFKDaGJQSik1iCYGpZRSg2hiUEopNYgm\nBqWUUoN4Za8kEakDjo/w8FjgpAvD8Qb6O/sH/Z19n7O/7wRjzLCrR3llYnCGiBScT3ctX6K/s3/Q\n39n3uev31VKSUkqpQTQxKKWUGsQfE8OTVgdgAf2d/YP+zr7PLb+v37UxKKWUOjd/vGJQSil1Dn6V\nGERkuYgcEJHDIvKw1fGMJhFJE5EtIlIsIkUi8k2rY3IXEQkQkV0iss7qWNxBRKJE5FUR2S8iJSKy\nwOqYRpuIPOR4XxeKyIsiEmp1TK4mIs+ISK2IFA7YFi0i+SJyyPFz/Gic228Sg4gEAL8FVgDZwB0i\nkm1tVKOqB/hnY0w2cAnwdR//fQf6Jn1TvPuL/we8ZYyZBuTi47+7iKQA3wDyjDEzgAD61nnxNX8C\nlp+x7WFgszEmC9jseOxyfpMYgHnAYWPMUWNMF/ASsMrimEaNMabKGPOp434LfR8WPr+mtoikAtcB\nT1kdizuISCRwBY61TIwxXcaYRmujcotAYIyIBAJhQKXF8bicMeZ9oOGMzauA5xz3nwNuHI1z+1Ni\nSAHKBjwuxw8+KAFEJAOYA3xsbSRu8SvgO4Dd6kDcJBOoA551lM+eEpFwq4MaTcaYCuBnwAmgCmgy\nxmyyNiq3STDGVDnuVwMJo3ESf0oMfklExgJ/B/6PMabZ6nhGk4hcD9QaYz6xOhY3CgTmAr8zxswB\nWhml8oKncNTVV9GXFJOBcBG5y9qo3M+xPPKodCv1p8RQAaQNeJzq2OazRCSIvqTwF2PMa1bH4wYL\ngZUiUkpfqXCRiPzZ2pBGXTlQbozpvxp8lb5E4csWA8eMMXXGmG7gNeBSi2NylxoRSQJw/KwdjZP4\nU2LYCWSJSKaIBNPXWLXW4phGjYgIfXXnEmPML6yOxx2MMY8YY1KNMRn0/f++Y4zx6W+SxphqoExE\npjo2XQMUWxiSO5wALhGRMMf7/Bp8vMF9gLXAPY779wBrRuMkgaPxop7IGNMjIg8CG+nrxfCMMabI\n4rBG00Lgy8A+Ednt2PY9Y8x6C2NSo+OfgL84vvAcBe6zOJ5RZYz5WEReBT6lr/fdLnxwBLSIvAhc\nBcSKSDnwQ+Bx4BURuZ++Gaa/OCrn1pHPSimlBvKnUpJSSqnzoIlBKaXUIJoYlFJKDaKJQSml1CCa\nGJRSSg2iiUEppdQgmhiUUkoNoolBKaXUIP8f1GdJKLcWdpAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108f6e828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "x = np.linspace(0,10,100)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Python Tutorials\n",
    "\n",
    "If you are looking to learn python from scratch or you may need to refresh your python skills, we recommend to check out this interactive python tutorial: https://www.learnpython.org\n",
    "\n",
    "Another machine learning oriented tutorial is at\n",
    "https://machinelearningmastery.com/machine-learning-in-python-step-by-step/\n",
    "(thanks to the recommendation from Eric Schultz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the 20 Newsgroups Dataset\n",
    "\n",
    "1. In **Project 1** we work with “20 Newsgroups” dataset. It is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups, each corresponding to a different topic. It is is splitted in two subsets: one for training (or development) and the other one for testing (or for performance evaluation) and is a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "2. The easiest way to load the data is to use the built-in dataset loader for \"20 newsgroups\" from scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Refer to the offcial document of scikit-learn for detailed usages:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "categories = ['comp.graphics', 'comp.sys.mac.hardware']\n",
    "# The \n",
    "twenty_train = fetch_20newsgroups(subset='train', # choose which subset of the dataset to use; can be 'train', 'test', 'all'\n",
    "                                  categories=categories, # choose the categories to load; if is `None`, load all categories\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42, # set the seed of random number generator when shuffling to make the outcome repeatable across different runs\n",
    "#                                   remove=['headers'],\n",
    "                                 )\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.datasets.base.Bunch'>\n",
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])\n"
     ]
    }
   ],
   "source": [
    "print(type(twenty_train))\n",
    "print(twenty_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/50423',\n",
       "       '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38237',\n",
       "       '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38277',\n",
       "       ...,\n",
       "       '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38592',\n",
       "       '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51688',\n",
       "       '/Users/nnguyen/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38739'], \n",
       "      dtype='<U95')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.filenames # the path to the text files storing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.filenames) # 1162 documents in the train subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data) # `twenty_train.data` or `twenty_train['data']` is the list storing document strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: winstead@faraday.ece.cmu.edu (Charles Holden Winstead)\n",
      "Subject: ftp site for Radius software???\n",
      "Organization: Electrical and Computer Engineering, Carnegie Mellon\n",
      "\n",
      "Hey All,\n",
      "\n",
      "Does anyone know if I can ftp to get the newest version of Radiusware\n",
      "and soft pivot from Radius?  I bought a pivot monitor, but it has an\n",
      "old version of this software and won't work on my C650, and Radius said\n",
      "it would be 4-5 weeks until delivery.\n",
      "\n",
      "Thanks!\n",
      "\n",
      "-Chuck\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0]) # the content of the first document is printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[0]) # the content of the first document is printed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of category indices of the documents\n",
    "twenty_train.target # twenty_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `twenty_train.target` only contains 0 and 1\n",
    "import numpy as np\n",
    "np.unique(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'comp.sys.mac.hardware']\n"
     ]
    }
   ],
   "source": [
    "# index 0 corresponds to 'comp.graphics'; 1 to 'comp.sys.mac.hardware'\n",
    "print(twenty_train.target_names) # twenty_train['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "# The first document belongs to the category 'comp.sys.mac.hardware'\n",
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files themselves are loaded in memory in the data attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1162\n",
      "1162\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.target))\n",
    "print(len(twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from text files\n",
    "\n",
    "### Bag of Words\n",
    "\n",
    "Bag of words is one of the simplest and most common representation of texts, where each document is represented by an unordered list (or a so-called \"bag\") of words.\n",
    "\n",
    "### Document-term Matrix\n",
    "\n",
    "$\\begin{pmatrix}tf(d_1, t_1) & \\cdots & tf(d_1, t_m) \\\\ tf(d_2, t_1) & \\cdots & tf(d_2, t_m) \\\\ \\vdots & \\vdots & \\vdots \\\\ tf(d_n, t_1) & \\cdots & tf(d_n, t_m) \\end{pmatrix}$\n",
    "\n",
    "$tf(d, t)$: term frequency of term $t$ in the document $d$, i.e. the number of occurrances of term $t$ in the document $d$.\n",
    "\n",
    "The class `CountVectorizer` can help us to convert a collection of text documents to a document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `min_df`, `max_df` and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 19610)\n",
      "(1162, 9420)\n",
      "(1162, 6348)\n",
      "(1162, 4867)\n"
     ]
    }
   ],
   "source": [
    "min_dfs = range(1,5)\n",
    "for min_df in min_dfs:\n",
    "    count_vect_tmp = CountVectorizer(min_df=min_df)\n",
    "    X_train_tmp = count_vect_tmp.fit_transform(twenty_train.data)\n",
    "    print(X_train_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopwords**: Words that are too common to be useful in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'nobody', 'every', 'eg', 'even', 'now', 'otherwise', 'whether', 'upon', 'my', 'whereupon', 'with', 'out', 'made', 'whither', 'de', 'again', 'could', 'along', 'elsewhere', 'four', 'myself', 'never', 'off', 'no', 'although', 'seem', 'else', 'been', 'fire', 'are', 'hereby', 'to', 'which', 'down', 'another', 'whereafter', 'whereby', 'there', 'however', 'put', 'still', 'amount', 'becomes', 'itself', 'herself', 'beforehand', 'sometime', 'hers', 'beside', 'eleven', 'because', 'sixty', 'towards', 'became', 'within', 'full', 'cant', 'noone', 'least', 'as', 'but', 'side', 'fill', 'if', 'an', 'either', 'twelve', 'give', 'hundred', 'cry', 'formerly', 'she', 'since', 'get', 'their', 'below', 'from', 'for', 'rather', 'each', 'wherever', 'bill', 'move', 'nothing', 'onto', 'ours', 'they', 'one', 'during', 'serious', 'whoever', 'being', 'why', 'indeed', 'go', 'same', 'who', 'yourself', 'into', 'ltd', 'sometimes', 'anyhow', 'themselves', 'after', 'thin', 'what', 'be', 'due', 'somehow', 'please', 'found', 'over', 'whenever', 'empty', 'us', 'inc', 'many', 'other', 'etc', 'or', 'thereafter', 'against', 'back', 'less', 'about', 'herein', 'more', 'find', 'therefore', 'thick', 'become', 'fifty', 'something', 'mine', 'all', 'throughout', 'so', 'was', 'should', 'enough', 'alone', 'its', 'moreover', 'neither', 'whom', 'anyone', 'behind', 'cannot', 'others', 'these', 'by', 'whatever', 'ourselves', 'may', 'thru', 'those', 'until', 'do', 'anyway', 'former', 'hereafter', 'ie', 'mostly', 'his', 'once', 'of', 'where', 'yours', 'it', 'thereby', 'and', 'at', 'will', 'five', 'take', 'everywhere', 'him', 'anywhere', 'everything', 'someone', 'you', 'six', 'afterwards', 'ever', 'amongst', 'amoungst', 'among', 'had', 'couldnt', 'bottom', 'except', 'any', 'none', 'meanwhile', 'a', 'perhaps', 'top', 'nine', 'that', 'both', 'though', 'were', 'nowhere', 'name', 'around', 'seemed', 'thus', 'whence', 'first', 'becoming', 'con', 'whole', 'together', 'while', 'her', 'always', 'somewhere', 'un', 'sincere', 'yet', 'almost', 'on', 'fifteen', 'ten', 'several', 'system', 'then', 'via', 'through', 'further', 'hereupon', 'is', 'nor', 'only', 'than', 'everyone', 'up', 'might', 'interest', 'before', 'must', 'some', 're', 'thence', 'toward', 'twenty', 'yourselves', 'per', 'forty', 'too', 'co', 'in', 'beyond', 'the', 'would', 'see', 'very', 'therein', 'well', 'your', 'such', 'whose', 'eight', 'most', 'anything', 'i', 'next', 'done', 'hence', 'three', 'not', 'has', 'namely', 'can', 'also', 'when', 'across', 'call', 'last', 'this', 'me', 'how', 'latterly', 'wherein', 'nevertheless', 'describe', 'hasnt', 'between', 'own', 'keep', 'latter', 'few', 'above', 'detail', 'whereas', 'seems', 'front', 'part', 'under', 'our', 'two', 'much', 'have', 'he', 'besides', 'often', 'here', 'third', 'we', 'without', 'am', 'show', 'seeming', 'himself', 'mill', 'already', 'thereupon', 'them'})\n",
      "318\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stop_words = text.ENGLISH_STOP_WORDS\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the detailed documentation of `CountVectorizer`, see\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Note: `fit`, `fit_transform`, `transform` are common methods of all kinds of data transformers in `scikit learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "# `fit_transform(corpus)` is equivalent to `fit(corpus)` then `transform(corpus)`\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use `toarray()` to convert sparse matrices to ordinary matrices (multi-dim arrays)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature names are terms\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = [\n",
    "    'Another random document.'\n",
    "]\n",
    "\n",
    "# Use `transform` instead of `fit_transform` here, to only count\n",
    "# terms that are in the vocabulary of the training dataset\n",
    "Y = vectorizer.transform(test_corpus)\n",
    "# Here 'Another' and 'random' are just ignored\n",
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1162, 6078)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count_vect = CountVectorizer(min_df=3)\n",
    "count_vect = CountVectorizer(min_df=3, stop_words='english')\n",
    "# count_vect = CountVectorizer(stop_words='english', min_df=3, max_df=0.7)\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape # 1162 docs, 19610 terms in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(774, 6078)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "X_test_counts.shape # 774 docs, 19610 terms in the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0010580b',\n",
       " '01',\n",
       " '02',\n",
       " '020',\n",
       " '0200',\n",
       " '03',\n",
       " '030',\n",
       " '04',\n",
       " '040',\n",
       " '05',\n",
       " '06',\n",
       " '060493101758',\n",
       " '0608',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '0953',\n",
       " '0x100',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '1010',\n",
       " '101010',\n",
       " '101e',\n",
       " '102',\n",
       " '102007',\n",
       " '1024',\n",
       " '1024x768',\n",
       " '105',\n",
       " '106',\n",
       " '109',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '1101',\n",
       " '11230',\n",
       " '113',\n",
       " '114158',\n",
       " '115',\n",
       " '115a',\n",
       " '11632',\n",
       " '11670',\n",
       " '1170',\n",
       " '12',\n",
       " '120',\n",
       " '12091',\n",
       " '123',\n",
       " '1246',\n",
       " '127',\n",
       " '128',\n",
       " '1280',\n",
       " '129',\n",
       " '13',\n",
       " '130',\n",
       " '1304',\n",
       " '1304s',\n",
       " '131',\n",
       " '131239',\n",
       " '132',\n",
       " '1320',\n",
       " '132mb',\n",
       " '133',\n",
       " '134',\n",
       " '13495',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '13h',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '141',\n",
       " '142',\n",
       " '1430',\n",
       " '144',\n",
       " '144750',\n",
       " '144843',\n",
       " '146',\n",
       " '147',\n",
       " '149',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '152944br4416a',\n",
       " '153',\n",
       " '15490',\n",
       " '155',\n",
       " '1568',\n",
       " '157',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '160x2xx',\n",
       " '163',\n",
       " '164940',\n",
       " '1653',\n",
       " '167',\n",
       " '16bit',\n",
       " '16mb',\n",
       " '16mhz',\n",
       " '17',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '175',\n",
       " '178',\n",
       " '18',\n",
       " '180',\n",
       " '181440',\n",
       " '182',\n",
       " '189',\n",
       " '19',\n",
       " '192',\n",
       " '192947',\n",
       " '193758',\n",
       " '19549',\n",
       " '1958',\n",
       " '1985',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1993apr10',\n",
       " '1993apr11',\n",
       " '1993apr13',\n",
       " '1993apr14',\n",
       " '1993apr15',\n",
       " '1993apr16',\n",
       " '1993apr17',\n",
       " '1993apr18',\n",
       " '1993apr19',\n",
       " '1993apr20',\n",
       " '1993apr22',\n",
       " '1993apr5',\n",
       " '1993apr6',\n",
       " '1d17',\n",
       " '1d20',\n",
       " '1m',\n",
       " '1mb',\n",
       " '1pscti',\n",
       " '1qkgbuinns9n',\n",
       " '1qksuq',\n",
       " '1quvdoinn3e7',\n",
       " '1st',\n",
       " '1tt8',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20084',\n",
       " '201',\n",
       " '2011',\n",
       " '203',\n",
       " '2039',\n",
       " '205',\n",
       " '206',\n",
       " '20664',\n",
       " '20771',\n",
       " '20mhz',\n",
       " '20ns',\n",
       " '21',\n",
       " '210',\n",
       " '21000',\n",
       " '212',\n",
       " '212441',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '216',\n",
       " '217',\n",
       " '22',\n",
       " '221',\n",
       " '2213',\n",
       " '223',\n",
       " '2240',\n",
       " '2246',\n",
       " '225',\n",
       " '227',\n",
       " '229',\n",
       " '2295',\n",
       " '23',\n",
       " '230',\n",
       " '233',\n",
       " '2333',\n",
       " '235',\n",
       " '24',\n",
       " '240',\n",
       " '2400',\n",
       " '2400bps',\n",
       " '241',\n",
       " '244',\n",
       " '246',\n",
       " '248',\n",
       " '249',\n",
       " '24bit',\n",
       " '24x',\n",
       " '25',\n",
       " '250',\n",
       " '252',\n",
       " '253',\n",
       " '254',\n",
       " '255',\n",
       " '256',\n",
       " '256k',\n",
       " '25mhz',\n",
       " '25x',\n",
       " '26',\n",
       " '27',\n",
       " '274',\n",
       " '275',\n",
       " '277',\n",
       " '28',\n",
       " '280',\n",
       " '286',\n",
       " '29',\n",
       " '295',\n",
       " '299',\n",
       " '2d',\n",
       " '2mb',\n",
       " '2nd',\n",
       " '2qz',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300i',\n",
       " '300k',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '305',\n",
       " '30fps',\n",
       " '31',\n",
       " '310',\n",
       " '312',\n",
       " '313',\n",
       " '316',\n",
       " '32',\n",
       " '320',\n",
       " '320x200',\n",
       " '320x200x256',\n",
       " '320x240',\n",
       " '32768',\n",
       " '32k',\n",
       " '33',\n",
       " '330',\n",
       " '334',\n",
       " '339',\n",
       " '33mhz',\n",
       " '34',\n",
       " '3401',\n",
       " '34125',\n",
       " '3426',\n",
       " '35',\n",
       " '350',\n",
       " '351',\n",
       " '35294',\n",
       " '354',\n",
       " '355',\n",
       " '36',\n",
       " '360',\n",
       " '368',\n",
       " '37',\n",
       " '3700',\n",
       " '376',\n",
       " '377',\n",
       " '38',\n",
       " '384',\n",
       " '386',\n",
       " '389',\n",
       " '39',\n",
       " '390',\n",
       " '3d',\n",
       " '3do',\n",
       " '3ds',\n",
       " '3fgx',\n",
       " '3jl',\n",
       " '3mb',\n",
       " '3rd',\n",
       " '3xx',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '402',\n",
       " '404',\n",
       " '405',\n",
       " '4060',\n",
       " '407',\n",
       " '408',\n",
       " '40mb',\n",
       " '40mhz',\n",
       " '40sc',\n",
       " '41',\n",
       " '4100',\n",
       " '415',\n",
       " '416',\n",
       " '42',\n",
       " '43',\n",
       " '433',\n",
       " '435',\n",
       " '43y',\n",
       " '44',\n",
       " '4400',\n",
       " '441',\n",
       " '44mb',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '480',\n",
       " '48109',\n",
       " '486',\n",
       " '486dx',\n",
       " '486dx2',\n",
       " '49',\n",
       " '495',\n",
       " '49546',\n",
       " '4d',\n",
       " '4fg',\n",
       " '4k',\n",
       " '4m',\n",
       " '4mb',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '508',\n",
       " '50mhz',\n",
       " '51',\n",
       " '510',\n",
       " '512',\n",
       " '512k',\n",
       " '515',\n",
       " '519',\n",
       " '52',\n",
       " '525',\n",
       " '53',\n",
       " '530',\n",
       " '534',\n",
       " '53c96',\n",
       " '54',\n",
       " '5473',\n",
       " '55',\n",
       " '5543',\n",
       " '56',\n",
       " '565',\n",
       " '57',\n",
       " '578',\n",
       " '57th',\n",
       " '58',\n",
       " '5841',\n",
       " '59',\n",
       " '5980',\n",
       " '5mb',\n",
       " '5mhz',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '601',\n",
       " '604',\n",
       " '60637',\n",
       " '60ns',\n",
       " '61',\n",
       " '610',\n",
       " '613',\n",
       " '615',\n",
       " '616',\n",
       " '617',\n",
       " '619',\n",
       " '62',\n",
       " '624',\n",
       " '62699',\n",
       " '627',\n",
       " '63',\n",
       " '64',\n",
       " '640',\n",
       " '6403',\n",
       " '640x400',\n",
       " '640x480',\n",
       " '640x480x16',\n",
       " '640x480x256',\n",
       " '64k',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '66mhz',\n",
       " '67',\n",
       " '68',\n",
       " '68000',\n",
       " '680000',\n",
       " '680020',\n",
       " '680030',\n",
       " '680040',\n",
       " '680060',\n",
       " '68010',\n",
       " '68020',\n",
       " '68030',\n",
       " '68040',\n",
       " '68060',\n",
       " '68070',\n",
       " '680x0',\n",
       " '685',\n",
       " '68lc040',\n",
       " '68rc040',\n",
       " '69',\n",
       " '696',\n",
       " '6mb',\n",
       " '6th',\n",
       " '6v2',\n",
       " '70',\n",
       " '700',\n",
       " '7000',\n",
       " '702',\n",
       " '703',\n",
       " '705',\n",
       " '708',\n",
       " '71',\n",
       " '72',\n",
       " '7311',\n",
       " '734',\n",
       " '74',\n",
       " '748',\n",
       " '75',\n",
       " '750',\n",
       " '76203',\n",
       " '763',\n",
       " '768',\n",
       " '77',\n",
       " '775',\n",
       " '776',\n",
       " '79',\n",
       " '791',\n",
       " '794',\n",
       " '7968',\n",
       " '7mhz',\n",
       " '7qo',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '800k',\n",
       " '800x600',\n",
       " '800x600x256',\n",
       " '801',\n",
       " '802',\n",
       " '80386',\n",
       " '805',\n",
       " '80mb',\n",
       " '80ns',\n",
       " '81',\n",
       " '817',\n",
       " '818',\n",
       " '82',\n",
       " '83',\n",
       " '832x624',\n",
       " '837',\n",
       " '838',\n",
       " '84',\n",
       " '848',\n",
       " '85',\n",
       " '8500',\n",
       " '8514',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '8900',\n",
       " '8900c',\n",
       " '895',\n",
       " '8bit',\n",
       " '8k',\n",
       " '8mb',\n",
       " '90',\n",
       " '900',\n",
       " '9000',\n",
       " '91',\n",
       " '91109',\n",
       " '92',\n",
       " '92093',\n",
       " '93',\n",
       " '93105',\n",
       " '934',\n",
       " '93apr20085951',\n",
       " '94',\n",
       " '94025',\n",
       " '94039',\n",
       " '94305',\n",
       " '95',\n",
       " '950',\n",
       " '957',\n",
       " '96',\n",
       " '9600',\n",
       " '964',\n",
       " '966',\n",
       " '97',\n",
       " '9760',\n",
       " '978',\n",
       " '98',\n",
       " '980',\n",
       " '99',\n",
       " '9pl',\n",
       " '_24x_',\n",
       " '__',\n",
       " '___',\n",
       " '____',\n",
       " '_____',\n",
       " '______',\n",
       " '_______',\n",
       " '________________',\n",
       " '_______________________________',\n",
       " '____________________________________',\n",
       " '________________________________________________________________',\n",
       " '_schnider',\n",
       " 'a0000',\n",
       " 'a1200',\n",
       " 'a2',\n",
       " 'a2i',\n",
       " 'aa',\n",
       " 'aaron',\n",
       " 'aau',\n",
       " 'ab',\n",
       " 'abad',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'absolutely',\n",
       " 'abstract',\n",
       " 'abstracts',\n",
       " 'ac',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'accel',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'accelerator',\n",
       " 'accelerators',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accesses',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accomplish',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accummulate',\n",
       " 'accumulate',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achive',\n",
       " 'acm',\n",
       " 'acns',\n",
       " 'acpub',\n",
       " 'acquisition',\n",
       " 'acs',\n",
       " 'acsc',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'ad994',\n",
       " 'adams',\n",
       " 'adamski',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaptor',\n",
       " 'adb',\n",
       " 'adc',\n",
       " 'add',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administrator',\n",
       " 'admit',\n",
       " 'adobe',\n",
       " 'ads',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'ae',\n",
       " 'aep',\n",
       " 'aerospace',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affiliated',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afi9shs00vohmrylee',\n",
       " 'afraid',\n",
       " 'aftersleep',\n",
       " 'agate',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agricultural',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aim',\n",
       " 'aimla',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'aix',\n",
       " 'aix02',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alan',\n",
       " 'alas',\n",
       " 'alberta',\n",
       " 'albuquerque',\n",
       " 'alchemy',\n",
       " 'aldus',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'algebraic',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'aliasing',\n",
       " 'alice',\n",
       " 'alignment',\n",
       " 'allen',\n",
       " 'alliant',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'almaden',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alt',\n",
       " 'altered',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'am2o',\n",
       " 'amann',\n",
       " 'amazing',\n",
       " 'amber',\n",
       " 'ambiguous',\n",
       " 'ameres',\n",
       " 'america',\n",
       " 'american',\n",
       " 'ames',\n",
       " 'amiga',\n",
       " 'amigas',\n",
       " 'aminet',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analyze',\n",
       " 'anarchal',\n",
       " 'andre',\n",
       " 'andreas',\n",
       " 'andreasa',\n",
       " 'andrem',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animations',\n",
       " 'animator',\n",
       " 'ann',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcements',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'anonymous',\n",
       " 'ansi',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'antonio',\n",
       " 'anu',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyways',\n",
       " 'aol',\n",
       " 'apana',\n",
       " 'apart',\n",
       " 'apda',\n",
       " 'api',\n",
       " 'apollo',\n",
       " 'app',\n",
       " 'apparantly',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'applelink',\n",
       " 'apples',\n",
       " 'appletalk',\n",
       " 'application',\n",
       " 'applications',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'apprecied',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'aps',\n",
       " 'aqe',\n",
       " 'aragorn',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arbor',\n",
       " 'arc',\n",
       " 'archer',\n",
       " 'archie',\n",
       " 'archimedes',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archive',\n",
       " 'archives',\n",
       " 'archiving',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arff',\n",
       " 'argue',\n",
       " 'ariadne',\n",
       " 'aris',\n",
       " 'arithmetic',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'armed',\n",
       " 'army',\n",
       " 'arno',\n",
       " 'aron',\n",
       " 'arpa',\n",
       " 'arranged',\n",
       " 'array',\n",
       " 'arrays',\n",
       " 'arrow',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artifacts',\n",
       " 'artist',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'artwork',\n",
       " 'asante',\n",
       " 'ascii',\n",
       " 'asd',\n",
       " 'ashley',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asm',\n",
       " 'aspects',\n",
       " 'assassin',\n",
       " 'assembled',\n",
       " 'assembler',\n",
       " 'assembly',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assisted',\n",
       " 'associated',\n",
       " 'associates',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assured',\n",
       " 'asterix',\n",
       " 'astronomical',\n",
       " 'atari',\n",
       " 'atheist',\n",
       " 'athena',\n",
       " 'athens',\n",
       " 'ati',\n",
       " 'atlanta',\n",
       " 'atmospheric',\n",
       " 'atoms',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attendees',\n",
       " 'attention',\n",
       " 'attest',\n",
       " 'attractive',\n",
       " 'attributes',\n",
       " 'au',\n",
       " 'audio',\n",
       " 'august',\n",
       " 'aus',\n",
       " 'austin',\n",
       " 'austlcm',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'authorized',\n",
       " 'authors',\n",
       " 'auto',\n",
       " 'autocad',\n",
       " 'autodesk',\n",
       " 'automated',\n",
       " 'automatic',\n",
       " 'automatically',\n",
       " 'autotrace',\n",
       " 'auvm',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'ave',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'axis',\n",
       " 'b0',\n",
       " 'b5l',\n",
       " 'b62182',\n",
       " 'background',\n",
       " 'backup',\n",
       " 'bad',\n",
       " 'bag',\n",
       " 'bailey',\n",
       " 'balki',\n",
       " 'ball',\n",
       " 'balsa',\n",
       " 'baltimore',\n",
       " 'bands',\n",
       " 'bandwidth',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barnsley',\n",
       " 'baron',\n",
       " 'barris',\n",
       " 'barry',\n",
       " 'bars',\n",
       " 'bart',\n",
       " 'bartokomas',\n",
       " 'base',\n",
       " 'based',\n",
       " 'bases',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'batch',\n",
       " 'batteries',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'baud',\n",
       " 'bauer',\n",
       " 'bay',\n",
       " 'bbn',\n",
       " 'bbs',\n",
       " 'bc',\n",
       " 'bcarm382',\n",
       " 'bchs',\n",
       " 'bcstec',\n",
       " 'beach',\n",
       " 'beam',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beautiful',\n",
       " 'beaver',\n",
       " 'beeing',\n",
       " 'beeps',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behr',\n",
       " 'believe',\n",
       " 'bell',\n",
       " 'bellcore',\n",
       " 'ben',\n",
       " 'benchmark',\n",
       " 'benchmarks',\n",
       " 'berkeley',\n",
       " 'berkshire',\n",
       " 'berlin',\n",
       " 'bernoulli',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'bethesda',\n",
       " 'better',\n",
       " 'beverly',\n",
       " 'beware',\n",
       " 'bezel',\n",
       " 'bezier',\n",
       " 'bga',\n",
       " 'bgi',\n",
       " 'bgx',\n",
       " 'bham',\n",
       " 'bibliography',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'billy',\n",
       " 'binaries',\n",
       " 'binary',\n",
       " 'binhex',\n",
       " 'bio',\n",
       " 'biology',\n",
       " 'bios',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'bisector',\n",
       " 'bit',\n",
       " 'bitmap',\n",
       " 'bitmapped',\n",
       " 'bitmaps',\n",
       " 'bitnet',\n",
       " 'bits',\n",
       " 'bizarre',\n",
       " 'black',\n",
       " 'blade',\n",
       " 'blanc',\n",
       " 'blank',\n",
       " 'blaze',\n",
       " 'blazes',\n",
       " 'bldg',\n",
       " 'blessed',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blockiness',\n",
       " 'blocks',\n",
       " 'blow',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature names list returned by `get_feature_names()` can be used as the mapping from column index to feature name ;\n",
    "\n",
    "The converse mapping from feature name to column index is stored in the `vocabulary_` attribute of the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6078"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue', 'blvd', 'bm967', 'bmp', 'bmug', 'bnr', 'board', 'boards', 'boat', 'bob', 'bobc', 'body', 'boeing', 'boesel', 'boisvert', 'boivert', 'bolero', 'bolson', 'bonar', 'boned']\n",
      "--------------------\n",
      "1313\n",
      "circuitry\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names()[1000:1020])\n",
    "print('-' * 20)\n",
    "print(count_vect.vocabulary_.get('circuitry'))\n",
    "print(count_vect.get_feature_names()[1313])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "TF-IDF score is used to describe \"how important a word is to a document in a collection or corpus\" (from [Wikipedia - tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf))\n",
    "\n",
    "$$TF\\times IDF(d,t)=tf(d,t)\\times idf(t)$$\n",
    "<hr>\n",
    "$$idf(t)=\\log(\\frac{n}{df(t)})+1$$\n",
    "\n",
    "- $tf(t, d)$: term frequency of term $t$ in the document $d$.\n",
    "\n",
    "\n",
    "- $idf(t)$: inverse document frequency of term $t$ across the document dataset.\n",
    "  - $df(t)$: # of documents that contain the term $t$.\n",
    "  - Intuition: words that appear in all documents are useless in classificaiton.\n",
    "  \n",
    "The formula that is used to compute the tf-idf of term t is tf-idf(d, t) = tf(t) * idf(d, t), and the idf is computed as idf(d, t) = log [ n / df(d, t) ] + 1 (if smooth_idf=False), where n is the total number of documents and df(d, t) is the document frequency; the document frequency is the number of documents d that contain term t. The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. (Note that the idf formula above differs from the standard textbook notation that defines the idf as idf(d, t) = log [ n / (df(d, t) + 1) ]).\n",
    "\n",
    "If smooth_idf=True (the default), the constant “1” is added to the numerator and denominator of the idf as if an extra document was seen containing every term in the collection exactly once, which prevents zero divisions: idf(d, t) = log [ (1 + n) / (1 + df(d, t)) ] + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 6078)\n",
      "--------------------\n",
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 2]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.08238187]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.1035171  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# recall that X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_train_counts.toarray()[:30,:5])\n",
    "print('-' * 20)\n",
    "print(X_train_tfidf.toarray()[:30,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier\n",
    "\n",
    "Let's train a classifier to predict the category of a post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use Naive Bayes classifier as an example\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'He is an OS developer' => comp.sys.mac.hardware\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['He is an OS developer', 'OpenGL on the GPU is fast']\n",
    "# ['comp.graphics', 'comp.sys.mac.hardware']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LinearSVC().fit(X_train_tfidf, twenty_train.target).predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF: Non-negative matrix factorization\n",
    "\\begin{array}{cc}\n",
    "\\min_\\limits{\\mathbf{W}, \\mathbf{H}} & \\lVert\\mathbf{X} - \\mathbf{W}\\mathbf{H}\\rVert_F^2 \\\\\n",
    "s.t. & \\mathbf{W} \\ge 0 \\\\\n",
    "& \\mathbf{H} \\ge 0\n",
    "\\end{array}\n",
    "\n",
    "$\\mathbf{X} \\in \\mathbb{R}^{m\\times n}$,\n",
    "\n",
    "$\\mathbf{W} \\in \\mathbb{R}^{m\\times k}$, $\\mathbf{H} \\in \\mathbb{R}^{k\\times n}$, $k < \\mathrm{rank}(\\mathbf{X})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=0)\n",
    "W_train = model.fit_transform(X_train_tfidf)\n",
    "\n",
    "print(W_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6078)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = model.components_\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'He is an OS developer' => comp.graphics\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "W_test = model.transform(X_new_tfidf)\n",
    "\n",
    "clf = MultinomialNB().fit(W_train, twenty_train.target)\n",
    "\n",
    "predicted = clf.predict(W_test)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "LinearSVC(loss='hinge',C=0.01).fit(W_train, twenty_train.target).predict(W_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA/LSI\n",
    "\n",
    "https://simonpaarlberg.com/post/latent-semantic-analyses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=0)\n",
    "X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
    "print(X_train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'He is an OS developer' => comp.graphics\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "X_new_reduced = model.transform(X_new_tfidf)\n",
    "\n",
    "clf = LinearSVC().fit(X_train_reduced, twenty_train.target)\n",
    "\n",
    "predicted = clf.predict(X_new_reduced)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK\n",
    "1. Download NLTK package\n",
    "  1. `conda install -c anaconda nltk` <br>or\n",
    "  2. `pip install nltk`\n",
    "2. Have the stopwords corpus on your computer\n",
    "  1. `nltk.download()` if you want to download any data in NLTK\n",
    "  2. instruction for downloading can be found http://www.nltk.org/data.html\n",
    "3. More detailed information can be found \n",
    "  1. http://www.nltk.org/api/nltk.stem.html#module-nltk.stem\n",
    "  2. https://www.kaggle.com/alvations/basic-nlp-with-nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of stop_words_skt:\t\t 318\n",
      "# of stop_words_en:\t\t 179\n",
      "# of punctuation:\t\t 32\n",
      "# of combined_stopwords:\t 410\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "stop_words_skt = text.ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords' )\n",
    "stop_words_en = stopwords.words('english')\n",
    "\n",
    "print(\"# of stop_words_skt:\\t\\t %s\" % len(stop_words_skt))\n",
    "print(\"# of stop_words_en:\\t\\t %s\" % len(stop_words_en))\n",
    "from string import punctuation\n",
    "print(\"# of punctuation:\\t\\t %s\" % len(punctuation))\n",
    "combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))\n",
    "print(\"# of combined_stopwords:\\t %s\" % len(combined_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "Often we want to map the different forms of the same word to the same root word, e.g. \"walks\", \"walking\", \"walked\" should all be the same as \"walk\".\n",
    "\n",
    "The stemming and lemmatization process are hand-written regex rules written find the root word.\n",
    "\n",
    "1. Stemming: Trying to shorten a word with simple regex rules\n",
    "\n",
    "2. Lemmatization: Trying to find the root word with linguistics rules (with the use of regexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- PorterStemmer --------------------\n",
      "grow\n",
      "doe\n",
      "leav\n",
      "fairli\n",
      "articl\n",
      "-------------------- SnowballStemmer --------------------\n",
      "grow\n",
      "doe\n",
      "leav\n",
      "fair\n",
      "articl\n"
     ]
    }
   ],
   "source": [
    "# popular stemmers\n",
    "import nltk\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "test_list = ['grows','does','leaves','fairly','article']\n",
    "print(\"-\"*20 + \" PorterStemmer \" + \"-\"*20)\n",
    "for item in test_list:\n",
    "    print(ps.stem(item))\n",
    "print(\"-\"*20 + \" SnowballStemmer \" + \"-\"*20)\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "for item in test_list:\n",
    "    print(sno.stem(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer\n",
    "1. Lemmatize using WordNet’s built-in morphy function. Returns the input word unchanged if it cannot be found in WordNet. The default pos=NOUN.\n",
    "2. The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "3. 'pos_tag' takes the tokenized sentence as input, i.e. list of string,and returns a tuple of (word, tg), i.e. list of tuples of strings\n",
    "  1. pos_tag uses  Penn Treebank http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "  2. We can just map some of them to wordnet\n",
    "  3. In the wordnet (ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v', POS_LIST = [NOUN, VERB, ADJ, ADV])\n",
    "     You can find detailed information here http://www.nltk.org/_modules/nltk/corpus/reader/wordnet.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- WordNetLemmatizer --------------------\n",
      "grows\n",
      "doe\n",
      "leaf\n",
      "fairly\n",
      "article\n",
      "-------------------- Another example for WordNetLemmatizer --------------------\n",
      "walking\n",
      "walk\n",
      "walked\n",
      "<WordNetLemmatizer>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()#, if you need \"corpora/wordnet\", choose it\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "#lemmatize(word, pos='n')\n",
    "print(\"-\"*20 + \" WordNetLemmatizer \" + \"-\"*20)\n",
    "for item in test_list:\n",
    "    print(wnl.lemmatize(item))\n",
    "print(\"-\"*20 + \" Another example for WordNetLemmatizer \" + \"-\"*20)\n",
    "for word in ['walking', 'walks', 'walked']:\n",
    "    print(wnl.lemmatize(word))\n",
    "print(wnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'PRP'), ('is', 'VBZ'), ('walking', 'VBG'), ('to', 'TO'), ('school', 'NN')]\n",
      "mapping to Verb, Noun, Adjective, Adverbial\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['he', 'be', 'walk', 'to', 'school']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one example for advanced stemming\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "walking_tagged = pos_tag(nltk.word_tokenize('He is walking to school'))\n",
    "print(walking_tagged)\n",
    "print(\"mapping to Verb, Noun, Adjective, Adverbial\")\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n' \n",
    "def lemmatize_sent_demo(text): \n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "def lemmatize_sent(list_word): \n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "lemmatize_sent_demo('He is walking to school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize -> stem -> remove punctuation & stop words\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "comp_categories = [ 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
    "rec_categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=comp_categories+rec_categories, shuffle=True, random_state=42,)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=comp_categories+rec_categories, shuffle=True, random_state=42,)\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4732"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer().build_analyzer()  \"\"\"Return a callable that handles preprocessing and tokenization\"\"\"\n",
    "https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/feature_extraction/text.py#L247\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "analyzer = TfidfVectorizer(stop_words=combined_stopwords, preprocessor=lambda doc: doc.translate(str.maketrans(dict.fromkeys('0123456789')))).build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overwrite analyzer with callable function:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if word not in combined_stopwords and not word.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 69068)\n",
      "(4732, 24849)\n",
      "(4732, 16292)\n",
      "(4732, 12640)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "min_dfs = range(1,5)\n",
    "for min_df in min_dfs:\n",
    "    count_vect1 = CountVectorizer(min_df=min_df,analyzer=stem_rmv_punc)\n",
    "    X_train_counts1 = count_vect1.fit_transform(twenty_train.data)\n",
    "    print(X_train_counts1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_vect1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "// add your CSS styling here\n",
    "</style>\n",
    "<style>\n",
    ".visualhide {\n",
    "    position: absolute;\n",
    "    left: -10000px;\n",
    "    top: auto;\n",
    "    width: 1px;\n",
    "    height: 1px;\n",
    "    overflow: hidden;\n",
    "}\n",
    "table.wikitable {\n",
    "    background-color: #f8f9fa;\n",
    "    color: #222;\n",
    "    margin: 1em 0;\n",
    "    border: 1px solid #a2a9b1;\n",
    "    border-collapse: collapse;\n",
    "}\n",
    ".rendered_html td {\n",
    "    text-align: center;\n",
    "}\n",
    ".rendered_html tbody tr:nth-child(odd) {\n",
    "    background: transparent;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "See [Wikipedia - Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "\n",
    "Each **row** of the matrix represents the instances in a **predicted class**<br> while each **column** represents the instances in an **actual class** (or vice versa).\n",
    "\n",
    "Many statistics can be derived from the **Confusion Matrix**.\n",
    "\n",
    "Below is an example for binary classification, where by convention we call one class as **Positive** and another as **Negative**.\n",
    "<table class=\"wikitable\" align=\"center\" style=\"text-align:center; border:none; background:transparent;\">\n",
    "<tbody><tr>\n",
    "<td style=\"border:none;\" colspan=\"2\"></td>\n",
    "<td style=\"background:#eeeebb;\" colspan=\"2\"><b>True condition</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border:none;\"></td>\n",
    "<td style=\"background:#dddddd;\"><a href=\"https://en.wikipedia.org/wiki/Statistical_population\" title=\"Statistical population\">Total population</a></td>\n",
    "<td style=\"background:#ffffcc;\">Condition positive</td>\n",
    "<td style=\"background:#ddddaa;\">Condition negative</td>\n",
    "<td style=\"background:#eeeecc;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/Prevalence\" title=\"Prevalence\">Prevalence</a> <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ&nbsp;Condition positive</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Total population</span></span></span></td>\n",
    "<td style=\"background:#cceecc;border-left:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision\" title=\"Accuracy and precision\">Accuracy</a> (ACC) = <span style=\"font-size:118%;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ&nbsp;True positive + Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Total population</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background:#bbeeee;\" rowspan=\"2\"><b>Predicted<br>\n",
    "condition</b></td>\n",
    "<td style=\"background:#ccffff;\">Predicted condition<br>\n",
    "positive</td>\n",
    "<td style=\"background:#ccffcc;\"><span style=\"color:#006600;\"><b><a href=\"https://en.wikipedia.org/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\">True positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Statistical_power\" title=\"Statistical power\">Power</a></span></td>\n",
    "<td style=\"background:#eedddd;\"><span style=\"color:#cc0000;\"><b><a href=\"https://en.wikipedia.org/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\">False positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_I_error\" class=\"mw-redirect\" title=\"Type I error\">Type I error</a></span></td>\n",
    "<td style=\"background:#ccffee;border-top:double silver;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/Positive_predictive_value\" class=\"mw-redirect\" title=\"Positive predictive value\">Positive predictive value</a> (PPV), <a href=\"https://en.wikipedia.org/wiki/Precision_(information_retrieval)\" class=\"mw-redirect\" title=\"Precision (information retrieval)\">Precision</a> = <span style=\"font-size:118%;white-space:nowrap;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background:#cceeff;border-top:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/False_discovery_rate\" title=\"False discovery rate\">False discovery rate</a> (FDR) = <span style=\"font-size:118%;white-space:nowrap;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background:#aadddd;\">Predicted condition<br>\n",
    "negative</td>\n",
    "<td style=\"background:#ffdddd;\"><span style=\"color:#cc0000;\"><b><a href=\"https://en.wikipedia.org/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\">False negative</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_II_error\" class=\"mw-redirect\" title=\"Type II error\">Type II error</a></span></td>\n",
    "<td style=\"background:#bbeebb;\"><span style=\"color:#006600;\"><b><a href=\"https://en.wikipedia.org/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\">True negative</a></b></span></td>\n",
    "<td style=\"background:#eeddee;border-bottom:double silver;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/False_omission_rate\" class=\"mw-redirect\" title=\"False omission rate\">False omission rate</a> (FOR) = <span style=\"font-size:118%;white-space:nowrap;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background:#aaddcc;border-bottom:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Negative_predictive_value\" class=\"mw-redirect\" title=\"Negative predictive value\">Negative predictive value</a> (NPV) = <span style=\"font-size:118%;white-space:nowrap;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size:90%;\">\n",
    "<td style=\"border:none;vertical-align:bottom;padding:0 2px 0 0;color:#999999;\" colspan=\"2\" rowspan=\"2\"></td>\n",
    "<td style=\"background:#eeffcc;\"><a href=\"https://en.wikipedia.org/wiki/True_positive_rate\" class=\"mw-redirect\" title=\"True positive rate\">True positive rate</a> (TPR), <a href=\"https://en.wikipedia.org/wiki/Recall_(information_retrieval)\" class=\"mw-redirect\" title=\"Recall (information retrieval)\">Recall</a>, <a href=\"https://en.wikipedia.org/wiki/Sensitivity_(tests)\" class=\"mw-redirect\" title=\"Sensitivity (tests)\">Sensitivity</a>, probability&nbsp;of&nbsp;detection <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background:#eeddbb;\"><a href=\"https://en.wikipedia.org/wiki/False_positive_rate\" title=\"False positive rate\">False positive rate</a> (FPR), <a href=\"https://en.wikipedia.org/wiki/Information_retrieval\" title=\"Information retrieval\"><span class=\"nowrap\">Fall-out</span></a>, probability&nbsp;of&nbsp;false&nbsp;alarm <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background:#eeeeee;\"><a href=\"https://en.wikipedia.org/wiki/Positive_likelihood_ratio\" class=\"mw-redirect\" title=\"Positive likelihood ratio\">Positive likelihood ratio</a> <span class=\"nowrap\">(LR+)</span> <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">TPR</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">FPR</span></span></span></td>\n",
    "<td style=\"background:#dddddd;\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\" title=\"Diagnostic odds ratio\">Diagnostic odds ratio</a> (DOR) <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">LR+</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">LR−</span></span></span></td>\n",
    "<td style=\"background:#ddffdd;border-left:double silver;line-height:2;\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/F1_score\" title=\"F1 score\">F<sub>1</sub> score</a> = <span style=\"font-size:118%;white-space:nowrap;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">2</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\"><span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">1</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Recall</span></span>&nbsp;+&nbsp;<span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">1</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Precision</span></span></span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size:90%;\">\n",
    "<td style=\"background:#ffeecc;\"><a href=\"https://en.wikipedia.org/wiki/False_negative_rate\" class=\"mw-redirect\" title=\"False negative rate\">False negative rate</a> (FNR), Miss&nbsp;rate <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background:#ddeebb;\"><a href=\"https://en.wikipedia.org/wiki/True_negative_rate\" class=\"mw-redirect\" title=\"True negative rate\">True negative rate</a> (TNR), <a href=\"https://en.wikipedia.org/wiki/Specificity_(tests)\" class=\"mw-redirect\" title=\"Specificity (tests)\">Specificity</a> (SPC) <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background:#cccccc;\"><a href=\"https://en.wikipedia.org/wiki/Negative_likelihood_ratio\" class=\"mw-redirect\" title=\"Negative likelihood ratio\">Negative likelihood ratio</a> <span class=\"nowrap\">(LR−)</span> <span style=\"font-size:118%;white-space:nowrap;\">= <span class=\"sfrac nowrap\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span style=\"display:block; line-height:1em; margin:0 0.1em;\">FNR</span><span class=\"visualhide\">/</span><span style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">TNR</span></span></span></td>\n",
    "</tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision and recall\n",
    "<table class=\"wikitable\" align=\"center\" style=\"text-align: center ; border: none ; background: transparent\">\n",
    "<tbody><tr>\n",
    "<td style=\"border: none\" colspan=\"2\"></td>\n",
    "<td style=\"background: #eeeebb\" colspan=\"2\"><b>True condition</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: none\"></td>\n",
    "<td style=\"background: #dddddd\"><a href=\"https://en.wikipedia.org/wiki/Statistical_population\" title=\"Statistical population\" target=\"_blank\">Total population</a></td>\n",
    "<td style=\"background: #ffffcc\">Condition positive</td>\n",
    "<td style=\"background: #ddddaa\">Condition negative</td>\n",
    "<td style=\"background: #eee ; font-size: 90%\"><a href=\"https://en.wikipedia.org/wiki/Prevalence\" title=\"Prevalence\" target=\"_blank\">Prevalence</a> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ&nbsp;Condition positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Total population</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-left: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision\" title=\"Accuracy and precision\" target=\"_blank\">Accuracy</a> (ACC) = <span style=\"font-size: 118%\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ&nbsp;True positive + Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Total population</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background: #bbeeee\" rowspan=\"2\"><b>Predicted<br>\n",
    "condition</b></td>\n",
    "<td style=\"background: #ccffff\">Predicted condition<br>\n",
    "positive</td>\n",
    "<td style=\"background: #ccffcc\"><span style=\"color: #006600\"><b><a href=\"https://en.wikipedia.org/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\" target=\"_blank\">True positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Statistical_power\" title=\"Statistical power\" target=\"_blank\">Power</a></span></td>\n",
    "<td style=\"background: #eedddd\"><span style=\"color: #cc0000\"><b><a href=\"https://en.wikipedia.org/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\" target=\"_blank\">False positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_I_error\" class=\"mw-redirect\" title=\"Type I error\" target=\"_blank\">Type I error</a></span></td>\n",
    "<td style=\"background: #ccffee;border-top: double silver;font-size: 90%;font-weight: bold;\"><a href=\"https://en.wikipedia.org/wiki/Positive_predictive_value\" class=\"mw-redirect\" title=\"Positive predictive value\" target=\"_blank\">Positive predictive value</a> (PPV), <a href=\"https://en.wikipedia.org/wiki/Precision_(information_retrieval)\" class=\"mw-redirect\" title=\"Precision (information retrieval)\" target=\"_blank\">Precision</a> = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-top: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/False_discovery_rate\" title=\"False discovery rate\" target=\"_blank\">False discovery rate</a> (FDR) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background: #aadddd\">Predicted condition<br>\n",
    "negative</td>\n",
    "<td style=\"background: #ffdddd\"><span style=\"color: #cc0000\"><b><a href=\"https://en.wikipedia.org/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\" target=\"_blank\">False negative</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_II_error\" class=\"mw-redirect\" title=\"Type II error\" target=\"_blank\">Type II error</a></span></td>\n",
    "<td style=\"background: #bbeebb\"><span style=\"color: #006600\"><b><a href=\"https://en.wikipedia.org/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\" target=\"_blank\">True negative</a></b></span></td>\n",
    "<td style=\"background: #eee ; border-bottom: double silver ; font-size: 90%\"><a href=\"https://en.wikipedia.org/wiki/False_omission_rate\" class=\"mw-redirect\" title=\"False omission rate\" target=\"_blank\">False omission rate</a> (FOR) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-bottom: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Negative_predictive_value\" class=\"mw-redirect\" title=\"Negative predictive value\" target=\"_blank\">Negative predictive value</a> (NPV) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size: 90%\">\n",
    "<td style=\"border: none ; vertical-align: bottom ; padding: 0 2px 0 0 ; color: #999999\" colspan=\"2\" rowspan=\"2\"></td>\n",
    "<td style=\"background: #eeffcc;font-weight: bold;\"><a href=\"https://en.wikipedia.org/wiki/True_positive_rate\" class=\"mw-redirect\" title=\"True positive rate\" target=\"_blank\">True positive rate</a> (TPR), <a href=\"https://en.wikipedia.org/wiki/Recall_(information_retrieval)\" class=\"mw-redirect\" title=\"Recall (information retrieval)\" target=\"_blank\">Recall</a>, <a href=\"https://en.wikipedia.org/wiki/Sensitivity_(tests)\" class=\"mw-redirect\" title=\"Sensitivity (tests)\" target=\"_blank\">Sensitivity</a>, probability&nbsp;of&nbsp;detection <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/False_positive_rate\" title=\"False positive rate\" target=\"_blank\">False positive rate</a> (FPR), <a href=\"https://en.wikipedia.org/wiki/Information_retrieval\" title=\"Information retrieval\" target=\"_blank\"><span class=\"nowrap\">Fall-out</span></a>, probability&nbsp;of&nbsp;false&nbsp;alarm <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eeeeee\"><a href=\"https://en.wikipedia.org/wiki/Positive_likelihood_ratio\" class=\"mw-redirect\" title=\"Positive likelihood ratio\" target=\"_blank\">Positive likelihood ratio</a> <span class=\"nowrap\">(LR+)</span> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">TPR</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">FPR</span></span></span></td>\n",
    "<td style=\"background: #eee\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\" title=\"Diagnostic odds ratio\" target=\"_blank\">Diagnostic odds ratio</a> (DOR) <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">LR+</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">LR−</span></span></span></td>\n",
    "<td style=\"background: #ddffdd;border-left: double silver;line-height: 2;font-weight: bold;\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/F1_score\" title=\"F1 score\" target=\"_blank\">F<sub>1</sub> score</a> = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">2</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">1</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Recall</span></span>&nbsp;+&nbsp;<span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">1</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Precision</span></span></span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size: 90%\">\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/False_negative_rate\" class=\"mw-redirect\" title=\"False negative rate\" target=\"_blank\">False negative rate</a> (FNR), Miss&nbsp;rate <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/True_negative_rate\" class=\"mw-redirect\" title=\"True negative rate\" target=\"_blank\">True negative rate</a> (TNR), <a href=\"https://en.wikipedia.org/wiki/Specificity_(tests)\" class=\"mw-redirect\" title=\"Specificity (tests)\" target=\"_blank\">Specificity</a> (SPC) <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/Negative_likelihood_ratio\" class=\"mw-redirect\" title=\"Negative likelihood ratio\" target=\"_blank\">Negative likelihood ratio</a> <span class=\"nowrap\">(LR−)</span> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">FNR</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">TNR</span></span></span></td>\n",
    "</tr>\n",
    "</tbody></table>\n",
    "\n",
    "- Looking at only one of them is not enough: e.g. a classifier classifying nearly everything to negative can have a high **precision**, but then its **recall** is low, and *vice versa*\n",
    "- Thus, $F_1$ score is designed to kind of combine the precision and recall together using harmonic average and gives out a comprehensive measure of the classification quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Receiver operating characteristic (ROC)\n",
    "<table class=\"wikitable\" align=\"center\" style=\"text-align: center ; border: none ; background: transparent\">\n",
    "<tbody><tr>\n",
    "<td style=\"border: none\" colspan=\"2\"></td>\n",
    "<td style=\"background: #eeeebb\" colspan=\"2\"><b>True condition</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"border: none\"></td>\n",
    "<td style=\"background: #dddddd\"><a href=\"https://en.wikipedia.org/wiki/Statistical_population\" title=\"Statistical population\" target=\"_blank\">Total population</a></td>\n",
    "<td style=\"background: #ffffcc\">Condition positive</td>\n",
    "<td style=\"background: #ddddaa\">Condition negative</td>\n",
    "<td style=\"background: #eee ; font-size: 90%\"><a href=\"https://en.wikipedia.org/wiki/Prevalence\" title=\"Prevalence\" target=\"_blank\">Prevalence</a> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ&nbsp;Condition positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Total population</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-left: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision\" title=\"Accuracy and precision\" target=\"_blank\">Accuracy</a> (ACC) = <span style=\"font-size: 118%\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ&nbsp;True positive + Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Total population</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background: #bbeeee\" rowspan=\"2\"><b>Predicted<br>\n",
    "condition</b></td>\n",
    "<td style=\"background: #ccffff\">Predicted condition<br>\n",
    "positive</td>\n",
    "<td style=\"background: #ccffcc\"><span style=\"color: #006600\"><b><a href=\"https://en.wikipedia.org/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\" target=\"_blank\">True positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Statistical_power\" title=\"Statistical power\" target=\"_blank\">Power</a></span></td>\n",
    "<td style=\"background: #eedddd\"><span style=\"color: #cc0000\"><b><a href=\"https://en.wikipedia.org/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\" target=\"_blank\">False positive</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_I_error\" class=\"mw-redirect\" title=\"Type I error\" target=\"_blank\">Type I error</a></span></td>\n",
    "<td style=\"background: #eee ; border-top: double silver ; font-size: 90%\"><a href=\"https://en.wikipedia.org/wiki/Positive_predictive_value\" class=\"mw-redirect\" title=\"Positive predictive value\" target=\"_blank\">Positive predictive value</a> (PPV), <a href=\"https://en.wikipedia.org/wiki/Precision_(information_retrieval)\" class=\"mw-redirect\" title=\"Precision (information retrieval)\" target=\"_blank\">Precision</a> = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-top: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/False_discovery_rate\" title=\"False discovery rate\" target=\"_blank\">False discovery rate</a> (FDR) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;positive</span></span></span></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"background: #aadddd\">Predicted condition<br>\n",
    "negative</td>\n",
    "<td style=\"background: #ffdddd\"><span style=\"color: #cc0000\"><b><a href=\"https://en.wikipedia.org/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\" target=\"_blank\">False negative</a></b>,<br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Type_II_error\" class=\"mw-redirect\" title=\"Type II error\" target=\"_blank\">Type II error</a></span></td>\n",
    "<td style=\"background: #bbeebb\"><span style=\"color: #006600\"><b><a href=\"https://en.wikipedia.org/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\" target=\"_blank\">True negative</a></b></span></td>\n",
    "<td style=\"background: #eee ; border-bottom: double silver ; font-size: 90%\"><a href=\"https://en.wikipedia.org/wiki/False_omission_rate\" class=\"mw-redirect\" title=\"False omission rate\" target=\"_blank\">False omission rate</a> (FOR) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eee ; border-bottom: double silver ; font-size: 90%\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Negative_predictive_value\" class=\"mw-redirect\" title=\"Negative predictive value\" target=\"_blank\">Negative predictive value</a> (NPV) = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Predicted&nbsp;condition&nbsp;negative</span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size: 90%\">\n",
    "<td style=\"border: none ; vertical-align: bottom ; padding: 0 2px 0 0 ; color: #999999\" colspan=\"2\" rowspan=\"2\"></td>\n",
    "<td style=\"background: #eeffcc; font-weight: bold\"><a href=\"https://en.wikipedia.org/wiki/True_positive_rate\" class=\"mw-redirect\" title=\"True positive rate\" target=\"_blank\">True positive rate</a> (TPR), <a href=\"https://en.wikipedia.org/wiki/Recall_(information_retrieval)\" class=\"mw-redirect\" title=\"Recall (information retrieval)\" target=\"_blank\">Recall</a>, <a href=\"https://en.wikipedia.org/wiki/Sensitivity_(tests)\" class=\"mw-redirect\" title=\"Sensitivity (tests)\" target=\"_blank\">Sensitivity</a>, probability&nbsp;of&nbsp;detection <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eeddbb; font-weight: bold\"><a href=\"https://en.wikipedia.org/wiki/False_positive_rate\" title=\"False positive rate\" target=\"_blank\">False positive rate</a> (FPR), <a href=\"https://en.wikipedia.org/wiki/Information_retrieval\" title=\"Information retrieval\" target=\"_blank\"><span class=\"nowrap\">Fall-out</span></a>, probability&nbsp;of&nbsp;false&nbsp;alarm <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False positive</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eeeeee\"><a href=\"https://en.wikipedia.org/wiki/Positive_likelihood_ratio\" class=\"mw-redirect\" title=\"Positive likelihood ratio\" target=\"_blank\">Positive likelihood ratio</a> <span class=\"nowrap\">(LR+)</span> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">TPR</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">FPR</span></span></span></td>\n",
    "<td style=\"background: #eee\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\" title=\"Diagnostic odds ratio\" target=\"_blank\">Diagnostic odds ratio</a> (DOR) <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">LR+</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">LR−</span></span></span></td>\n",
    "<td style=\"background: #eee;border-left: double silver;line-height: 2;\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/F1_score\" title=\"F1 score\" target=\"_blank\">F<sub>1</sub> score</a> = <span style=\"font-size: 118% ; white-space: nowrap\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">2</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\"><span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">1</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Recall</span></span>&nbsp;+&nbsp;<span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">1</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Precision</span></span></span></span></span></td>\n",
    "</tr>\n",
    "<tr style=\"font-size: 90%\">\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/False_negative_rate\" class=\"mw-redirect\" title=\"False negative rate\" target=\"_blank\">False negative rate</a> (FNR), Miss&nbsp;rate <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ False negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;positive</span></span></span></td>\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/True_negative_rate\" class=\"mw-redirect\" title=\"True negative rate\" target=\"_blank\">True negative rate</a> (TNR), <a href=\"https://en.wikipedia.org/wiki/Specificity_(tests)\" class=\"mw-redirect\" title=\"Specificity (tests)\" target=\"_blank\">Specificity</a> (SPC) <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">Σ True negative</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">Σ&nbsp;Condition&nbsp;negative</span></span></span></td>\n",
    "<td style=\"background: #eee\"><a href=\"https://en.wikipedia.org/wiki/Negative_likelihood_ratio\" class=\"mw-redirect\" title=\"Negative likelihood ratio\" target=\"_blank\">Negative likelihood ratio</a> <span class=\"nowrap\">(LR−)</span> <span style=\"font-size: 118% ; white-space: nowrap\">= <span class=\"sfrac nowrap\" style=\"display: inline-block ; vertical-align: -0.5em ; font-size: 85% ; text-align: center\"><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em\">FNR</span><span class=\"visualhide\">/</span><span style=\"display: block ; line-height: 1em ; margin: 0 0.1em ; border-top: 1px solid\">TNR</span></span></span></td>\n",
    "</tr>\n",
    "</tbody></table>\n",
    "\n",
    "Interactive example: http://arogozhnikov.github.io/2015/10/05/roc-curve.html\n",
    "  - Blue distribution: Condition positive<br>\n",
    "  - Red distribution: Condition negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline in sklearn http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# toy demo\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y = np.array([1, 1, 2, 2])\n",
    "scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
    "print fpr\n",
    "print tpr\n",
    "print thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['comp.graphics', 'comp.sys.mac.hardware']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class SparseToDenseArray(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        if hasattr(X, 'toarray'):\n",
    "            return X.toarray()\n",
    "        return X\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# nmf = NMF(n_components=50, init='random', random_state=0)\n",
    "\n",
    "# \"The purpose of the pipeline is to assemble several steps that can \n",
    "#  be cross-validated together while setting different parameters.\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline1 = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', NMF(n_components=50, init='random', random_state=0)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', NMF(n_components=50, init='random', random_state=0)),\n",
    "    ('toarr', SparseToDenseArray()),\n",
    "    ('clf', GaussianNB()),\n",
    "])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, lw=2, label= 'area under curve = %0.4f' % roc_auc)\n",
    "\n",
    "    ax.grid(color='0.7', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate',fontsize=15)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=15)\n",
    "\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    for label in ax.get_xticklabels()+ax.get_yticklabels():\n",
    "        label.set_fontsize(15)\n",
    "\n",
    "def fit_predict_and_plot_roc(pipe, train_data, train_label, test_data, test_label):\n",
    "    pipe.fit(train_data, train_label)\n",
    "    # pipeline1.predict(twenty_test.data)\n",
    "\n",
    "    prob_score = pipe.predict_proba(test_data)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(test_label, prob_score[:,1])\n",
    "\n",
    "    plot_roc(fpr, tpr)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fit_predict_and_plot_roc(pipeline1, twenty_train.data, twenty_train.target, twenty_test.data, twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit_predict_and_plot_roc(pipeline2, twenty_train.data, twenty_train.target, twenty_test.data, twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GaussianNB classifier doesn't work well with sparse data, in which\n",
    "# case the predict_proba(test_data) gives out binary results\n",
    "pipeline2.set_params(reduce_dim=None)\n",
    "fit_predict_and_plot_roc(pipeline2, twenty_train.data, twenty_train.target, twenty_test.data, twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and Grid Search of Parameters\n",
    "\n",
    "So far, we have gone through the complete process of training and testing a classifier. You may have found that there are lots of parameters that we can tune. For example, when we extract the features, we can choose different `min_df`, `max_df`, exclude different stopwords, use different tokenizer and stemmer/lemmatizer. Then we can choose different values for `k` if we decide to perform dimensionality reduction. We can choose the type of classifier, and for a specific classifier, there may be more parameters that we can tune...\n",
    "\n",
    "What's worse, the performance of the classification is not necessarily (actually very probably not) monotonically dependent on each parameter, with other parameters fixed.\n",
    "\n",
    "Thus, to fine-tune the parameters, we need to perform grid search in a (empirically determined) parameter range. This can be wickedly tedious if we do it by hand. Luckily, `scikit-learn` provides us with a set of tools to automate such mechanical and repetitive work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
